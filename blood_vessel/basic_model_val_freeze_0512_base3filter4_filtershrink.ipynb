{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import multi_gpu_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support,roc_curve,auc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "import pandas as pd\n",
    "from keras import losses\n",
    "from skimage.io import imsave, imread\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dgxadmin/gcubme_ai/Workspace/JW_Seo/DVT_detection/Radiomics/code/deep_learning'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_block(inputs, filters = 4, scale = 2):\n",
    "    \n",
    "#     x = Conv2D(filters, 3, strides= 1, activation=None, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation(activation='relu')(x)\n",
    "   \n",
    "    x = Conv2D(filters, 3, strides=1, activation=None, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    base_out = Activation(activation='relu')(x)\n",
    "\n",
    "    \n",
    "    return base_out\n",
    "\n",
    "def bottleneck(inputs, filters):\n",
    "\n",
    "    x = Conv2D(filters, 1, activation=None, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, 3, activation=None, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, 1, activation=None, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "\n",
    "    return x\n",
    "\n",
    "def residual_block(inputs, filters):\n",
    "    \n",
    "    shortcut = inputs\n",
    "    print('input')\n",
    "    print('shortcut:',shortcut.shape)\n",
    "    print('x:',inputs.shape)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=3, strides=1, activation=None, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = bottleneck(x, filters)\n",
    "    \n",
    "    shortcut = Conv2D(filters, kernel_size=1, strides=1, activation=None, padding='same', kernel_initializer='he_normal')(shortcut)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "#     shrotcut = Activation(activation='relu')(shrotcut)\n",
    "    print('before add')\n",
    "    print('shortcut:',shortcut.shape)\n",
    "    print('x:',x.shape)\n",
    "    x = add([x, shortcut])\n",
    "    \n",
    "    res_out = Activation(activation='relu')(x)\n",
    "    \n",
    "    return res_out\n",
    "\n",
    "def res_block(inputs, filters):\n",
    "    \n",
    "    shortcut = inputs\n",
    "    \n",
    "    shrotcut = Conv2D(filters, 1, activation=None, padding='same', kernel_initializer='he_normal')(shortcut)\n",
    "    shrotcut = BatchNormalization()(shrotcut)\n",
    "    shrotcut = Activation(activation='relu')(shrotcut)\n",
    "    \n",
    "    x = Conv2D(filters, 1, activation=None, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, 3, activation=None, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, 1, activation=None, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    x = add([x, shortcut])\n",
    "    \n",
    "    res_out = Activation(activation='relu')(x)\n",
    "    \n",
    "    return res_out\n",
    "def base_classification_jw(inputs, filters = 4, scale = 2):\n",
    "    \n",
    "    layer=2\n",
    "    for br in range(layer):\n",
    "        \n",
    "        if br == 0:\n",
    "            print(br)\n",
    "            conv= base_block(inputs)\n",
    "            \n",
    "            conv = MaxPooling2D(pool_size=(3, 3), strides = 2)(conv)\n",
    "            print(conv.shape)\n",
    "            \n",
    "        else:\n",
    "            print(br)\n",
    "            print(conv.shape, scale, br, filters)\n",
    "            num = (scale**br) *  filters\n",
    "#             conv= residual_block(conv, filters= num)\n",
    "            conv= base_block(conv, filters= num)\n",
    "            print(conv.shape)\n",
    "            print(num)\n",
    "    \n",
    "            conv= MaxPooling2D(pool_size=(2, 2), strides = 2)(conv)\n",
    "            print(conv.shape)\n",
    "    for ar in range(layer):\n",
    "        print(num)\n",
    "        num = int(num/scale)\n",
    "        conv = base_block(conv, filters = num)\n",
    "        print(num)    \n",
    "        \n",
    "            \n",
    "    out= Flatten()(conv)\n",
    "  \n",
    "    out = Dense(1, activation=\"sigmoid\")(out)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "    \n",
    "    return model           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "WARNING:tensorflow:From /home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "(?, 15, 15, 4)\n",
      "1\n",
      "(?, 15, 15, 4) 2 1 4\n",
      "(?, 15, 15, 8)\n",
      "8\n",
      "(?, 7, 7, 8)\n",
      "8\n",
      "4\n",
      "4\n",
      "2\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 4)         40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 4)         16        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 4)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 8)         296       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 15, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 15, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 4)           292       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 4)           16        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 4)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 2)           74        \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 2)           8         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7, 7, 2)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 99        \n",
      "=================================================================\n",
      "Total params: 873\n",
      "Trainable params: 837\n",
      "Non-trainable params: 36\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "input_img = Input(shape=(32,32,1))\n",
    "model = base_classification_jw(input_img, filters = 4, scale = 2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(pred, test_y):\n",
    "    tp=0\n",
    "    fp=0\n",
    "    tn=0\n",
    "    fn=0\n",
    "    alpha = 0.0001\n",
    "    for cm in range(len(test_y)):\n",
    "        if list(test_y)[cm]==0:\n",
    "            if pred[cm]<0.5:\n",
    "                tn+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "        else:\n",
    "            if pred[cm]<0.5:\n",
    "                fp+=1\n",
    "            else:\n",
    "                tp+=1\n",
    "    print(tp, fp, tn, fn)\n",
    "    sensitivity= (tp+alpha)/(tp+fn+alpha)\n",
    "    specificity= (tn+alpha)/(tn+fp+alpha) \n",
    "    acc = (tp+tn+alpha)/(tp+fp+tn+fn+alpha)\n",
    "    prec = tp+alpha/(tp+fp+alpha)\n",
    "\n",
    "    return tp, fp, tn, fn, sensitivity, specificity, acc, prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1447\n",
      "1\n",
      "1597\n",
      "2\n",
      "1714\n",
      "3\n",
      "2406\n",
      "4\n",
      "1448\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "abList = sorted(glob.glob('../../data/abnormal/*'))\n",
    "nList = sorted(glob.glob('../../data/normal/*'))\n",
    "split = round(len(abList)/k)\n",
    "for s in range(k):\n",
    "    print(s)\n",
    "    a=0\n",
    "    for sp in range(split):\n",
    "        check = sorted(glob.glob(abList[s*sp+sp]+'/*.png'))\n",
    "        a+=len(check)\n",
    "    print(a)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1624, 32, 32, 1) (1624,)\n",
      "StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
      "TRAIN: 1299 TEST: 325\n",
      "RETRAIN: 1300 RETEST: 324\n",
      "(1300, 32, 32, 1) (324, 32, 32, 1)\n",
      "163 1 0 973\n",
      "TRAIN: 1299 TEST: 325\n",
      "RETRAIN: 1300 RETEST: 324\n",
      "(1300, 32, 32, 1) (324, 32, 32, 1)\n",
      "0 164 163 1135\n",
      "TRAIN: 1299 TEST: 325\n",
      "RETRAIN: 1300 RETEST: 324\n",
      "(1300, 32, 32, 1) (324, 32, 32, 1)\n",
      "0 327 326 1298\n",
      "TRAIN: 1299 TEST: 325\n",
      "RETRAIN: 1300 RETEST: 324\n",
      "(1300, 32, 32, 1) (324, 32, 32, 1)\n",
      "0 489 488 1461\n",
      "TRAIN: 1300 TEST: 324\n",
      "RETRAIN: 1300 RETEST: 324\n",
      "(1300, 32, 32, 1) (324, 32, 32, 1)\n",
      "0 650 1461 1623\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k=5\n",
    "\n",
    "abnormal = np.load('../../data/npy/abnormal_16to32.npy')\n",
    "normal = np.load('../../data/npy/normal_16to32.npy')\n",
    "data_x = np.concatenate((normal, abnormal))\n",
    "data_y = np.ndarray((len(data_x)),dtype=np.float32)\n",
    "for n in range(len(data_x)):\n",
    "    if n < len(normal):\n",
    "        data_y[n] = 0\n",
    "    else:\n",
    "        data_y[n] = 1\n",
    "print(data_x.shape, data_y.shape)        \n",
    "# train_x,train_x,test_y,test_y = train_test_split(data_x,data_y, stratify = data_y, train_size=1300, random_state = 25)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k)\n",
    "skf.get_n_splits(data_x,data_y)\n",
    "print(skf)\n",
    "i=0\n",
    "for train_index, test_index in skf.split(data_x,data_y):\n",
    "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "    indexs = np.concatenate((train_index, test_index), axis= 0)\n",
    "    train_index = indexs[:1300]\n",
    "    test_index = indexs[1300:]\n",
    "    print(\"RETRAIN:\", len(train_index), \"RETEST:\", len(test_index))\n",
    "    train_x, test_x = data_x[train_index], data_x[test_index]\n",
    "    train_y, test_y = data_y[train_index], data_y[test_index]\n",
    "    print(train_x.shape, test_x.shape)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    print(train_index[0],test_index[0],train_index[len(train_index)-1],test_index[len(test_index)-1])\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(train_x[0], cmap='gray')\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(test_x[0], cmap='gray')\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(train_x[len(train_x)-1], cmap='gray')\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(test_x[len(test_x)-1], cmap='gray')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "performances = np.ndarray((k,4), dtype=np.float32)\n",
    "\n",
    "for train_index, test_index in skf.split(data_x,data_y):\n",
    "    print(i)\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 1299 TEST: 325\n",
      "0\n",
      "(?, 15, 15, 4)\n",
      "1\n",
      "(?, 15, 15, 4) 2 1 4\n",
      "(?, 15, 15, 8)\n",
      "8\n",
      "(?, 7, 7, 8)\n",
      "8\n",
      "4\n",
      "4\n",
      "2\n",
      "WARNING:tensorflow:From /home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/dgxadmin/anaconda3/envs/zzaem2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1040 samples, validate on 259 samples\n",
      "Epoch 1/500\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.9438 - accuracy: 0.5019 - val_loss: 6.1023 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.10230, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 2/500\n",
      "1040/1040 [==============================] - 0s 175us/step - loss: 0.6765 - accuracy: 0.5615 - val_loss: 2.1936 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.10230 to 2.19356, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 3/500\n",
      "1040/1040 [==============================] - 0s 118us/step - loss: 0.5068 - accuracy: 0.8010 - val_loss: 0.7378 - val_accuracy: 0.5212\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.19356 to 0.73776, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 4/500\n",
      "1040/1040 [==============================] - 0s 107us/step - loss: 0.3887 - accuracy: 0.9048 - val_loss: 0.6782 - val_accuracy: 0.5907\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.73776 to 0.67824, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 5/500\n",
      "1040/1040 [==============================] - 0s 130us/step - loss: 0.3083 - accuracy: 0.9221 - val_loss: 0.7003 - val_accuracy: 0.5753\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.67824\n",
      "Epoch 6/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.2551 - accuracy: 0.9356 - val_loss: 0.6567 - val_accuracy: 0.5792\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.67824 to 0.65672, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 7/500\n",
      "1040/1040 [==============================] - 0s 93us/step - loss: 0.2199 - accuracy: 0.9433 - val_loss: 0.6169 - val_accuracy: 0.5946\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.65672 to 0.61690, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 8/500\n",
      "1040/1040 [==============================] - 0s 123us/step - loss: 0.1972 - accuracy: 0.9452 - val_loss: 0.6007 - val_accuracy: 0.6139\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.61690 to 0.60066, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 9/500\n",
      "1040/1040 [==============================] - 0s 120us/step - loss: 0.1827 - accuracy: 0.9471 - val_loss: 0.5971 - val_accuracy: 0.6255\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.60066 to 0.59711, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 10/500\n",
      "1040/1040 [==============================] - 0s 161us/step - loss: 0.1729 - accuracy: 0.9471 - val_loss: 0.5979 - val_accuracy: 0.6371\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.59711\n",
      "Epoch 11/500\n",
      "1040/1040 [==============================] - 0s 175us/step - loss: 0.1657 - accuracy: 0.9471 - val_loss: 0.6001 - val_accuracy: 0.6448\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.59711\n",
      "Epoch 12/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.1602 - accuracy: 0.9471 - val_loss: 0.5952 - val_accuracy: 0.6564\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.59711 to 0.59522, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 13/500\n",
      "1040/1040 [==============================] - 0s 113us/step - loss: 0.1557 - accuracy: 0.9481 - val_loss: 0.5764 - val_accuracy: 0.6834\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.59522 to 0.57642, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 14/500\n",
      "1040/1040 [==============================] - 0s 111us/step - loss: 0.1519 - accuracy: 0.9490 - val_loss: 0.5407 - val_accuracy: 0.7181\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.57642 to 0.54068, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 15/500\n",
      "1040/1040 [==============================] - 0s 120us/step - loss: 0.1486 - accuracy: 0.9500 - val_loss: 0.4960 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.54068 to 0.49601, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 16/500\n",
      "1040/1040 [==============================] - 0s 118us/step - loss: 0.1456 - accuracy: 0.9510 - val_loss: 0.4467 - val_accuracy: 0.7722\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.49601 to 0.44674, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 17/500\n",
      "1040/1040 [==============================] - 0s 135us/step - loss: 0.1429 - accuracy: 0.9519 - val_loss: 0.3974 - val_accuracy: 0.7992\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.44674 to 0.39742, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 18/500\n",
      "1040/1040 [==============================] - 0s 75us/step - loss: 0.1403 - accuracy: 0.9529 - val_loss: 0.3486 - val_accuracy: 0.8185\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.39742 to 0.34858, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 19/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.1377 - accuracy: 0.9538 - val_loss: 0.3017 - val_accuracy: 0.8494\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.34858 to 0.30169, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 20/500\n",
      "1040/1040 [==============================] - 0s 134us/step - loss: 0.1353 - accuracy: 0.9538 - val_loss: 0.2646 - val_accuracy: 0.8726\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.30169 to 0.26461, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 21/500\n",
      "1040/1040 [==============================] - 0s 79us/step - loss: 0.1328 - accuracy: 0.9558 - val_loss: 0.2340 - val_accuracy: 0.8842\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.26461 to 0.23403, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 22/500\n",
      "1040/1040 [==============================] - 0s 138us/step - loss: 0.1303 - accuracy: 0.9567 - val_loss: 0.2090 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23403 to 0.20903, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 23/500\n",
      "1040/1040 [==============================] - 0s 112us/step - loss: 0.1279 - accuracy: 0.9577 - val_loss: 0.1896 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.20903 to 0.18957, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 24/500\n",
      "1040/1040 [==============================] - 0s 155us/step - loss: 0.1257 - accuracy: 0.9577 - val_loss: 0.1730 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.18957 to 0.17303, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 25/500\n",
      "1040/1040 [==============================] - 0s 120us/step - loss: 0.1235 - accuracy: 0.9587 - val_loss: 0.1603 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.17303 to 0.16034, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 26/500\n",
      "1040/1040 [==============================] - 0s 123us/step - loss: 0.1213 - accuracy: 0.9587 - val_loss: 0.1496 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.16034 to 0.14957, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 27/500\n",
      "1040/1040 [==============================] - 0s 124us/step - loss: 0.1192 - accuracy: 0.9587 - val_loss: 0.1405 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.14957 to 0.14054, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 28/500\n",
      "1040/1040 [==============================] - 0s 144us/step - loss: 0.1170 - accuracy: 0.9587 - val_loss: 0.1320 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14054 to 0.13205, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 29/500\n",
      "1040/1040 [==============================] - 0s 132us/step - loss: 0.1148 - accuracy: 0.9596 - val_loss: 0.1249 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.13205 to 0.12491, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 30/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.1126 - accuracy: 0.9606 - val_loss: 0.1188 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.12491 to 0.11883, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 31/500\n",
      "1040/1040 [==============================] - 0s 131us/step - loss: 0.1103 - accuracy: 0.9615 - val_loss: 0.1135 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.11883 to 0.11349, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 32/500\n",
      "1040/1040 [==============================] - 0s 189us/step - loss: 0.1081 - accuracy: 0.9635 - val_loss: 0.1089 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.11349 to 0.10885, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 33/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.1057 - accuracy: 0.9635 - val_loss: 0.1047 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.10885 to 0.10474, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 34/500\n",
      "1040/1040 [==============================] - 0s 146us/step - loss: 0.1034 - accuracy: 0.9644 - val_loss: 0.1011 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.10474 to 0.10106, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 35/500\n",
      "1040/1040 [==============================] - 0s 133us/step - loss: 0.1010 - accuracy: 0.9663 - val_loss: 0.0979 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.10106 to 0.09792, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 36/500\n",
      "1040/1040 [==============================] - 0s 123us/step - loss: 0.0986 - accuracy: 0.9673 - val_loss: 0.0953 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.09792 to 0.09525, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 37/500\n",
      "1040/1040 [==============================] - 0s 152us/step - loss: 0.0962 - accuracy: 0.9683 - val_loss: 0.0930 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.09525 to 0.09301, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 38/500\n",
      "1040/1040 [==============================] - 0s 129us/step - loss: 0.0938 - accuracy: 0.9692 - val_loss: 0.0908 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.09301 to 0.09080, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 39/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.0914 - accuracy: 0.9692 - val_loss: 0.0885 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.09080 to 0.08853, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 40/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.0889 - accuracy: 0.9692 - val_loss: 0.0867 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.08853 to 0.08672, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 41/500\n",
      "1040/1040 [==============================] - 0s 119us/step - loss: 0.0865 - accuracy: 0.9702 - val_loss: 0.0855 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.08672 to 0.08549, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 42/500\n",
      "1040/1040 [==============================] - 0s 155us/step - loss: 0.0841 - accuracy: 0.9721 - val_loss: 0.0844 - val_accuracy: 0.9807\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.08549 to 0.08438, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 43/500\n",
      "1040/1040 [==============================] - 0s 135us/step - loss: 0.0818 - accuracy: 0.9731 - val_loss: 0.0829 - val_accuracy: 0.9807\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.08438 to 0.08291, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 44/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.0795 - accuracy: 0.9731 - val_loss: 0.0813 - val_accuracy: 0.9807\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.08291 to 0.08134, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 45/500\n",
      "1040/1040 [==============================] - 0s 113us/step - loss: 0.0773 - accuracy: 0.9731 - val_loss: 0.0798 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.08134 to 0.07984, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 46/500\n",
      "1040/1040 [==============================] - 0s 122us/step - loss: 0.0751 - accuracy: 0.9750 - val_loss: 0.0783 - val_accuracy: 0.9807\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.07984 to 0.07831, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 47/500\n",
      "1040/1040 [==============================] - 0s 136us/step - loss: 0.0729 - accuracy: 0.9760 - val_loss: 0.0768 - val_accuracy: 0.9807\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.07831 to 0.07679, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 48/500\n",
      "1040/1040 [==============================] - 0s 144us/step - loss: 0.0708 - accuracy: 0.9760 - val_loss: 0.0755 - val_accuracy: 0.9807\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.07679 to 0.07554, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 49/500\n",
      "1040/1040 [==============================] - 0s 124us/step - loss: 0.0688 - accuracy: 0.9788 - val_loss: 0.0746 - val_accuracy: 0.9807\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.07554 to 0.07464, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 50/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.0668 - accuracy: 0.9788 - val_loss: 0.0741 - val_accuracy: 0.9807\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.07464 to 0.07407, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 51/500\n",
      "1040/1040 [==============================] - 0s 164us/step - loss: 0.0649 - accuracy: 0.9788 - val_loss: 0.0738 - val_accuracy: 0.9807\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.07407 to 0.07378, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 52/500\n",
      "1040/1040 [==============================] - 0s 113us/step - loss: 0.0629 - accuracy: 0.9808 - val_loss: 0.0737 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.07378 to 0.07370, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 53/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.0611 - accuracy: 0.9808 - val_loss: 0.0736 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.07370 to 0.07360, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 54/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.0734 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.07360 to 0.07340, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 55/500\n",
      "1040/1040 [==============================] - 0s 171us/step - loss: 0.0576 - accuracy: 0.9817 - val_loss: 0.0732 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.07340 to 0.07324, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 56/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.0558 - accuracy: 0.9817 - val_loss: 0.0729 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.07324 to 0.07285, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 57/500\n",
      "1040/1040 [==============================] - 0s 125us/step - loss: 0.0543 - accuracy: 0.9817 - val_loss: 0.0717 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.07285 to 0.07173, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 58/500\n",
      "1040/1040 [==============================] - 0s 131us/step - loss: 0.0526 - accuracy: 0.9817 - val_loss: 0.0715 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.07173 to 0.07148, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 59/500\n",
      "1040/1040 [==============================] - 0s 108us/step - loss: 0.0510 - accuracy: 0.9827 - val_loss: 0.0713 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.07148 to 0.07128, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 60/500\n",
      "1040/1040 [==============================] - 0s 113us/step - loss: 0.0495 - accuracy: 0.9837 - val_loss: 0.0708 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.07128 to 0.07079, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 61/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.0479 - accuracy: 0.9856 - val_loss: 0.0700 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.07079 to 0.07000, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 62/500\n",
      "1040/1040 [==============================] - 0s 137us/step - loss: 0.0465 - accuracy: 0.9856 - val_loss: 0.0689 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.07000 to 0.06885, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 63/500\n",
      "1040/1040 [==============================] - 0s 110us/step - loss: 0.0451 - accuracy: 0.9875 - val_loss: 0.0679 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.06885 to 0.06789, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 64/500\n",
      "1040/1040 [==============================] - 0s 122us/step - loss: 0.0438 - accuracy: 0.9885 - val_loss: 0.0675 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.06789 to 0.06747, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 65/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.0425 - accuracy: 0.9894 - val_loss: 0.0666 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.06747 to 0.06658, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 66/500\n",
      "1040/1040 [==============================] - 0s 108us/step - loss: 0.0411 - accuracy: 0.9894 - val_loss: 0.0661 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.06658 to 0.06609, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 67/500\n",
      "1040/1040 [==============================] - 0s 145us/step - loss: 0.0399 - accuracy: 0.9894 - val_loss: 0.0657 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.06609 to 0.06567, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 68/500\n",
      "1040/1040 [==============================] - 0s 130us/step - loss: 0.0386 - accuracy: 0.9923 - val_loss: 0.0649 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.06567 to 0.06487, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 69/500\n",
      "1040/1040 [==============================] - 0s 153us/step - loss: 0.0373 - accuracy: 0.9923 - val_loss: 0.0637 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06487 to 0.06367, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 70/500\n",
      "1040/1040 [==============================] - 0s 131us/step - loss: 0.0361 - accuracy: 0.9933 - val_loss: 0.0630 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06367 to 0.06300, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 71/500\n",
      "1040/1040 [==============================] - 0s 119us/step - loss: 0.0350 - accuracy: 0.9933 - val_loss: 0.0629 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06300 to 0.06293, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 72/500\n",
      "1040/1040 [==============================] - 0s 146us/step - loss: 0.0339 - accuracy: 0.9933 - val_loss: 0.0623 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06293 to 0.06226, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 73/500\n",
      "1040/1040 [==============================] - 0s 211us/step - loss: 0.0328 - accuracy: 0.9933 - val_loss: 0.0618 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06226 to 0.06184, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 74/500\n",
      "1040/1040 [==============================] - 0s 120us/step - loss: 0.0318 - accuracy: 0.9933 - val_loss: 0.0612 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06184 to 0.06117, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 75/500\n",
      "1040/1040 [==============================] - 0s 146us/step - loss: 0.0308 - accuracy: 0.9933 - val_loss: 0.0605 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06117 to 0.06051, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 76/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.0298 - accuracy: 0.9933 - val_loss: 0.0601 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06051 to 0.06013, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 77/500\n",
      "1040/1040 [==============================] - 0s 131us/step - loss: 0.0289 - accuracy: 0.9933 - val_loss: 0.0593 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06013 to 0.05930, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 78/500\n",
      "1040/1040 [==============================] - 0s 147us/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 0.0588 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05930 to 0.05883, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 79/500\n",
      "1040/1040 [==============================] - 0s 77us/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.0586 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05883 to 0.05858, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 80/500\n",
      "1040/1040 [==============================] - 0s 124us/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.0582 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05858 to 0.05819, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 81/500\n",
      "1040/1040 [==============================] - 0s 138us/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.0582 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.05819 to 0.05817, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 82/500\n",
      "1040/1040 [==============================] - 0s 154us/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.0582 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05817 to 0.05816, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 83/500\n",
      "1040/1040 [==============================] - 0s 132us/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.0578 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05816 to 0.05782, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 84/500\n",
      "1040/1040 [==============================] - 0s 136us/step - loss: 0.0232 - accuracy: 0.9942 - val_loss: 0.0577 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.05782 to 0.05770, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 85/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.0574 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.05770 to 0.05740, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 86/500\n",
      "1040/1040 [==============================] - 0s 116us/step - loss: 0.0219 - accuracy: 0.9952 - val_loss: 0.0573 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.05740 to 0.05725, saving model to ./210512_basic_freeze/model/base3_filter4_fold0_0512.h5\n",
      "Epoch 87/500\n",
      "1040/1040 [==============================] - 0s 158us/step - loss: 0.0212 - accuracy: 0.9962 - val_loss: 0.0574 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.05725\n",
      "Epoch 88/500\n",
      "1040/1040 [==============================] - 0s 205us/step - loss: 0.0205 - accuracy: 0.9962 - val_loss: 0.0573 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.05725\n",
      "Epoch 89/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.0199 - accuracy: 0.9981 - val_loss: 0.0574 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05725\n",
      "Epoch 90/500\n",
      "1040/1040 [==============================] - 0s 110us/step - loss: 0.0192 - accuracy: 0.9981 - val_loss: 0.0577 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05725\n",
      "Epoch 91/500\n",
      "1040/1040 [==============================] - 0s 132us/step - loss: 0.0186 - accuracy: 0.9981 - val_loss: 0.0582 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05725\n",
      "Epoch 92/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.0180 - accuracy: 0.9981 - val_loss: 0.0585 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.05725\n",
      "Epoch 93/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.0175 - accuracy: 0.9981 - val_loss: 0.0588 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05725\n",
      "Epoch 94/500\n",
      "1040/1040 [==============================] - 0s 83us/step - loss: 0.0170 - accuracy: 0.9990 - val_loss: 0.0584 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05725\n",
      "Epoch 95/500\n",
      "1040/1040 [==============================] - 0s 166us/step - loss: 0.0169 - accuracy: 0.9990 - val_loss: 0.0583 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.05725\n",
      "Epoch 96/500\n",
      "1040/1040 [==============================] - 0s 210us/step - loss: 0.0168 - accuracy: 0.9990 - val_loss: 0.0582 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05725\n",
      "Epoch 97/500\n",
      "1040/1040 [==============================] - 0s 129us/step - loss: 0.0168 - accuracy: 0.9990 - val_loss: 0.0582 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.05725\n",
      "Epoch 98/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.0167 - accuracy: 0.9990 - val_loss: 0.0581 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05725\n",
      "Epoch 99/500\n",
      "1040/1040 [==============================] - 0s 122us/step - loss: 0.0167 - accuracy: 0.9990 - val_loss: 0.0580 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.05725\n",
      "Epoch 100/500\n",
      "1040/1040 [==============================] - 0s 142us/step - loss: 0.0166 - accuracy: 0.9990 - val_loss: 0.0580 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.05725\n",
      "Epoch 101/500\n",
      "1040/1040 [==============================] - 0s 80us/step - loss: 0.0166 - accuracy: 0.9990 - val_loss: 0.0581 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.05725\n",
      "Epoch 102/500\n",
      "1040/1040 [==============================] - 0s 120us/step - loss: 0.0165 - accuracy: 0.9990 - val_loss: 0.0582 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.05725\n",
      "Epoch 103/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.0165 - accuracy: 0.9990 - val_loss: 0.0583 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.05725\n",
      "Epoch 104/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0585 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.05725\n",
      "Epoch 105/500\n",
      "1040/1040 [==============================] - 0s 159us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0586 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.05725\n",
      "Epoch 106/500\n",
      "1040/1040 [==============================] - 0s 162us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0587 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.05725\n",
      "Epoch 107/500\n",
      "1040/1040 [==============================] - 0s 249us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0589 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.05725\n",
      "Epoch 108/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0590 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.05725\n",
      "Epoch 109/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0592 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.05725\n",
      "Epoch 110/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0593 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.05725\n",
      "Epoch 111/500\n",
      "1040/1040 [==============================] - 0s 132us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0594 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.05725\n",
      "Epoch 112/500\n",
      "1040/1040 [==============================] - 0s 125us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0595 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.05725\n",
      "Epoch 113/500\n",
      "1040/1040 [==============================] - 0s 100us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0596 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.05725\n",
      "Epoch 114/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0596 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.05725\n",
      "Epoch 115/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0597 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.05725\n",
      "Epoch 116/500\n",
      "1040/1040 [==============================] - 0s 119us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0598 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.05725\n",
      "Epoch 117/500\n",
      "1040/1040 [==============================] - 0s 123us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0598 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.05725\n",
      "Epoch 118/500\n",
      "1040/1040 [==============================] - 0s 118us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0599 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.05725\n",
      "Epoch 119/500\n",
      "1040/1040 [==============================] - 0s 158us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0599 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.05725\n",
      "Epoch 120/500\n",
      "1040/1040 [==============================] - 0s 95us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0599 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.05725\n",
      "Epoch 121/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0600 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.05725\n",
      "Epoch 122/500\n",
      "1040/1040 [==============================] - 0s 118us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0600 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.05725\n",
      "Epoch 123/500\n",
      "1040/1040 [==============================] - 0s 140us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0600 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.05725\n",
      "Epoch 124/500\n",
      "1040/1040 [==============================] - 0s 133us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0600 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.05725\n",
      "Epoch 125/500\n",
      "1040/1040 [==============================] - 0s 145us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0601 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.05725\n",
      "Epoch 126/500\n",
      "1040/1040 [==============================] - 0s 98us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0601 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.05725\n",
      "Epoch 127/500\n",
      "1040/1040 [==============================] - 0s 153us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0601 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.05725\n",
      "Epoch 128/500\n",
      "1040/1040 [==============================] - 0s 167us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0601 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.05725\n",
      "Epoch 129/500\n",
      "1040/1040 [==============================] - 0s 107us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0601 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.05725\n",
      "Epoch 130/500\n",
      "1040/1040 [==============================] - 0s 111us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0601 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.05725\n",
      "Epoch 131/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0601 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.05725\n",
      "Epoch 132/500\n",
      "1040/1040 [==============================] - 0s 150us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0601 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.05725\n",
      "Epoch 133/500\n",
      "1040/1040 [==============================] - 0s 85us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0601 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.05725\n",
      "Epoch 134/500\n",
      "1040/1040 [==============================] - 0s 137us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.05725\n",
      "Epoch 135/500\n",
      "1040/1040 [==============================] - 0s 133us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.05725\n",
      "Epoch 136/500\n",
      "1040/1040 [==============================] - 0s 125us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.05725\n",
      "Epoch 137/500\n",
      "1040/1040 [==============================] - 0s 131us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.05725\n",
      "Epoch 138/500\n",
      "1040/1040 [==============================] - 0s 136us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.05725\n",
      "Epoch 139/500\n",
      "1040/1040 [==============================] - 0s 159us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.05725\n",
      "Epoch 140/500\n",
      "1040/1040 [==============================] - 0s 168us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.05725\n",
      "Epoch 141/500\n",
      "1040/1040 [==============================] - 0s 139us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.05725\n",
      "Epoch 142/500\n",
      "1040/1040 [==============================] - 0s 132us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.05725\n",
      "Epoch 143/500\n",
      "1040/1040 [==============================] - 0s 135us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.05725\n",
      "Epoch 144/500\n",
      "1040/1040 [==============================] - 0s 163us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.05725\n",
      "Epoch 145/500\n",
      "1040/1040 [==============================] - 0s 101us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.05725\n",
      "Epoch 146/500\n",
      "1040/1040 [==============================] - 0s 109us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.05725\n",
      "Epoch 147/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.05725\n",
      "Epoch 148/500\n",
      "1040/1040 [==============================] - 0s 111us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.05725\n",
      "Epoch 149/500\n",
      "1040/1040 [==============================] - 0s 116us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.05725\n",
      "Epoch 150/500\n",
      "1040/1040 [==============================] - 0s 151us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.05725\n",
      "Epoch 151/500\n",
      "1040/1040 [==============================] - 0s 79us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.05725\n",
      "Epoch 152/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.05725\n",
      "Epoch 153/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.05725\n",
      "Epoch 154/500\n",
      "1040/1040 [==============================] - 0s 140us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.05725\n",
      "Epoch 155/500\n",
      "1040/1040 [==============================] - 0s 169us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.05725\n",
      "Epoch 156/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.05725\n",
      "Epoch 157/500\n",
      "1040/1040 [==============================] - 0s 165us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.05725\n",
      "Epoch 158/500\n",
      "1040/1040 [==============================] - 0s 83us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.05725\n",
      "Epoch 159/500\n",
      "1040/1040 [==============================] - 0s 124us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.05725\n",
      "Epoch 160/500\n",
      "1040/1040 [==============================] - 0s 122us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.05725\n",
      "Epoch 161/500\n",
      "1040/1040 [==============================] - 0s 122us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.05725\n",
      "Epoch 162/500\n",
      "1040/1040 [==============================] - 0s 163us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.05725\n",
      "Epoch 163/500\n",
      "1040/1040 [==============================] - 0s 177us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.05725\n",
      "Epoch 164/500\n",
      "1040/1040 [==============================] - 0s 154us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.05725\n",
      "Epoch 165/500\n",
      "1040/1040 [==============================] - 0s 93us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.05725\n",
      "Epoch 166/500\n",
      "1040/1040 [==============================] - 0s 120us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.05725\n",
      "Epoch 167/500\n",
      "1040/1040 [==============================] - 0s 116us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.05725\n",
      "Epoch 168/500\n",
      "1040/1040 [==============================] - 0s 110us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.05725\n",
      "Epoch 169/500\n",
      "1040/1040 [==============================] - 0s 133us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.05725\n",
      "Epoch 170/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.05725\n",
      "Epoch 171/500\n",
      "1040/1040 [==============================] - 0s 82us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.05725\n",
      "Epoch 172/500\n",
      "1040/1040 [==============================] - 0s 135us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.05725\n",
      "Epoch 173/500\n",
      "1040/1040 [==============================] - 0s 176us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.05725\n",
      "Epoch 174/500\n",
      "1040/1040 [==============================] - 0s 132us/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.05725\n",
      "Epoch 00174: early stopping\n",
      "TRAIN: 1299 TEST: 325\n",
      "0\n",
      "(?, 15, 15, 4)\n",
      "1\n",
      "(?, 15, 15, 4) 2 1 4\n",
      "(?, 15, 15, 8)\n",
      "8\n",
      "(?, 7, 7, 8)\n",
      "8\n",
      "4\n",
      "4\n",
      "2\n",
      "Train on 1040 samples, validate on 259 samples\n",
      "Epoch 1/500\n",
      "1040/1040 [==============================] - 1s 1ms/step - loss: 0.7455 - accuracy: 0.4423 - val_loss: 0.6743 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67431, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 2/500\n",
      "1040/1040 [==============================] - 0s 129us/step - loss: 0.5975 - accuracy: 0.7125 - val_loss: 0.6686 - val_accuracy: 0.5328\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67431 to 0.66858, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 3/500\n",
      "1040/1040 [==============================] - 0s 160us/step - loss: 0.4999 - accuracy: 0.8365 - val_loss: 0.6880 - val_accuracy: 0.5135\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.66858\n",
      "Epoch 4/500\n",
      "1040/1040 [==============================] - 0s 83us/step - loss: 0.4092 - accuracy: 0.8942 - val_loss: 0.6837 - val_accuracy: 0.5676\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.66858\n",
      "Epoch 5/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.3314 - accuracy: 0.9279 - val_loss: 0.6639 - val_accuracy: 0.6178\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.66858 to 0.66392, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 6/500\n",
      "1040/1040 [==============================] - 0s 144us/step - loss: 0.2756 - accuracy: 0.9288 - val_loss: 0.6468 - val_accuracy: 0.5792\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.66392 to 0.64684, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 7/500\n",
      "1040/1040 [==============================] - 0s 173us/step - loss: 0.2363 - accuracy: 0.9394 - val_loss: 0.6291 - val_accuracy: 0.6216\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.64684 to 0.62911, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 8/500\n",
      "1040/1040 [==============================] - 0s 160us/step - loss: 0.2087 - accuracy: 0.9481 - val_loss: 0.6149 - val_accuracy: 0.6062\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.62911 to 0.61488, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 9/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.1889 - accuracy: 0.9471 - val_loss: 0.5992 - val_accuracy: 0.6139\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.61488 to 0.59918, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 10/500\n",
      "1040/1040 [==============================] - 0s 132us/step - loss: 0.1743 - accuracy: 0.9529 - val_loss: 0.5796 - val_accuracy: 0.6602\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.59918 to 0.57960, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 11/500\n",
      "1040/1040 [==============================] - 0s 168us/step - loss: 0.1630 - accuracy: 0.9510 - val_loss: 0.5589 - val_accuracy: 0.6680\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.57960 to 0.55886, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 12/500\n",
      "1040/1040 [==============================] - 0s 175us/step - loss: 0.1542 - accuracy: 0.9538 - val_loss: 0.5378 - val_accuracy: 0.7181\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.55886 to 0.53783, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 13/500\n",
      "1040/1040 [==============================] - 0s 154us/step - loss: 0.1470 - accuracy: 0.9538 - val_loss: 0.5149 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.53783 to 0.51490, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 14/500\n",
      "1040/1040 [==============================] - 0s 123us/step - loss: 0.1409 - accuracy: 0.9558 - val_loss: 0.4862 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.51490 to 0.48623, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 15/500\n",
      "1040/1040 [==============================] - 0s 103us/step - loss: 0.1358 - accuracy: 0.9577 - val_loss: 0.4546 - val_accuracy: 0.7799\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.48623 to 0.45459, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 16/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.1311 - accuracy: 0.9587 - val_loss: 0.4208 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.45459 to 0.42083, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 17/500\n",
      "1040/1040 [==============================] - 0s 144us/step - loss: 0.1269 - accuracy: 0.9596 - val_loss: 0.3885 - val_accuracy: 0.8224\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.42083 to 0.38846, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 18/500\n",
      "1040/1040 [==============================] - 0s 162us/step - loss: 0.1230 - accuracy: 0.9606 - val_loss: 0.3608 - val_accuracy: 0.8494\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.38846 to 0.36083, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 19/500\n",
      "1040/1040 [==============================] - 0s 120us/step - loss: 0.1196 - accuracy: 0.9625 - val_loss: 0.3391 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.36083 to 0.33912, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 20/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.1165 - accuracy: 0.9625 - val_loss: 0.3181 - val_accuracy: 0.8726\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.33912 to 0.31808, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 21/500\n",
      "1040/1040 [==============================] - 0s 71us/step - loss: 0.1137 - accuracy: 0.9644 - val_loss: 0.2957 - val_accuracy: 0.8803\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.31808 to 0.29570, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 22/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.1110 - accuracy: 0.9654 - val_loss: 0.2740 - val_accuracy: 0.8919\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.29570 to 0.27396, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 23/500\n",
      "1040/1040 [==============================] - 0s 152us/step - loss: 0.1085 - accuracy: 0.9654 - val_loss: 0.2548 - val_accuracy: 0.9035\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.27396 to 0.25483, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 24/500\n",
      "1040/1040 [==============================] - 0s 159us/step - loss: 0.1062 - accuracy: 0.9673 - val_loss: 0.2412 - val_accuracy: 0.9112\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.25483 to 0.24116, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 25/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.1041 - accuracy: 0.9683 - val_loss: 0.2295 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.24116 to 0.22948, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 26/500\n",
      "1040/1040 [==============================] - 0s 118us/step - loss: 0.1019 - accuracy: 0.9673 - val_loss: 0.2190 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.22948 to 0.21897, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 27/500\n",
      "1040/1040 [==============================] - 0s 118us/step - loss: 0.0997 - accuracy: 0.9692 - val_loss: 0.2111 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.21897 to 0.21109, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 28/500\n",
      "1040/1040 [==============================] - 0s 138us/step - loss: 0.0977 - accuracy: 0.9692 - val_loss: 0.2052 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.21109 to 0.20523, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 29/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.0957 - accuracy: 0.9702 - val_loss: 0.2010 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.20523 to 0.20096, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 30/500\n",
      "1040/1040 [==============================] - 0s 132us/step - loss: 0.0937 - accuracy: 0.9721 - val_loss: 0.1977 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20096 to 0.19772, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 31/500\n",
      "1040/1040 [==============================] - 0s 106us/step - loss: 0.0917 - accuracy: 0.9721 - val_loss: 0.1945 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19772 to 0.19446, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 32/500\n",
      "1040/1040 [==============================] - 0s 119us/step - loss: 0.0897 - accuracy: 0.9731 - val_loss: 0.1914 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19446 to 0.19144, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 33/500\n",
      "1040/1040 [==============================] - 0s 152us/step - loss: 0.0877 - accuracy: 0.9731 - val_loss: 0.1886 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19144 to 0.18863, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 34/500\n",
      "1040/1040 [==============================] - 0s 86us/step - loss: 0.0857 - accuracy: 0.9740 - val_loss: 0.1870 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.18863 to 0.18701, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 35/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.0838 - accuracy: 0.9740 - val_loss: 0.1854 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.18701 to 0.18542, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 36/500\n",
      "1040/1040 [==============================] - 0s 132us/step - loss: 0.0820 - accuracy: 0.9740 - val_loss: 0.1845 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18542 to 0.18451, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 37/500\n",
      "1040/1040 [==============================] - 0s 140us/step - loss: 0.0802 - accuracy: 0.9750 - val_loss: 0.1838 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18451 to 0.18381, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 38/500\n",
      "1040/1040 [==============================] - 0s 151us/step - loss: 0.0784 - accuracy: 0.9760 - val_loss: 0.1829 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.18381 to 0.18291, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 39/500\n",
      "1040/1040 [==============================] - 0s 116us/step - loss: 0.0768 - accuracy: 0.9760 - val_loss: 0.1823 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18291 to 0.18229, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 40/500\n",
      "1040/1040 [==============================] - 0s 78us/step - loss: 0.0751 - accuracy: 0.9760 - val_loss: 0.1818 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18229 to 0.18177, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 41/500\n",
      "1040/1040 [==============================] - 0s 119us/step - loss: 0.0734 - accuracy: 0.9769 - val_loss: 0.1814 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.18177 to 0.18144, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 42/500\n",
      "1040/1040 [==============================] - 0s 137us/step - loss: 0.0718 - accuracy: 0.9769 - val_loss: 0.1808 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.18144 to 0.18083, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 43/500\n",
      "1040/1040 [==============================] - 0s 149us/step - loss: 0.0703 - accuracy: 0.9779 - val_loss: 0.1801 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.18083 to 0.18013, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 44/500\n",
      "1040/1040 [==============================] - 0s 105us/step - loss: 0.0688 - accuracy: 0.9779 - val_loss: 0.1797 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.18013 to 0.17970, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 45/500\n",
      "1040/1040 [==============================] - 0s 118us/step - loss: 0.0673 - accuracy: 0.9779 - val_loss: 0.1790 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.17970 to 0.17902, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 46/500\n",
      "1040/1040 [==============================] - 0s 144us/step - loss: 0.0658 - accuracy: 0.9779 - val_loss: 0.1788 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.17902 to 0.17878, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 47/500\n",
      "1040/1040 [==============================] - 0s 172us/step - loss: 0.0644 - accuracy: 0.9788 - val_loss: 0.1782 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.17878 to 0.17821, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 48/500\n",
      "1040/1040 [==============================] - 0s 123us/step - loss: 0.0629 - accuracy: 0.9788 - val_loss: 0.1771 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.17821 to 0.17708, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 49/500\n",
      "1040/1040 [==============================] - 0s 125us/step - loss: 0.0615 - accuracy: 0.9798 - val_loss: 0.1771 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.17708 to 0.17706, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 50/500\n",
      "1040/1040 [==============================] - 0s 101us/step - loss: 0.0601 - accuracy: 0.9798 - val_loss: 0.1775 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.17706\n",
      "Epoch 51/500\n",
      "1040/1040 [==============================] - 0s 137us/step - loss: 0.0588 - accuracy: 0.9808 - val_loss: 0.1780 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.17706\n",
      "Epoch 52/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.0576 - accuracy: 0.9827 - val_loss: 0.1780 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.17706\n",
      "Epoch 53/500\n",
      "1040/1040 [==============================] - 0s 162us/step - loss: 0.0563 - accuracy: 0.9827 - val_loss: 0.1777 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.17706\n",
      "Epoch 54/500\n",
      "1040/1040 [==============================] - 0s 124us/step - loss: 0.0551 - accuracy: 0.9837 - val_loss: 0.1777 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.17706\n",
      "Epoch 55/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.0539 - accuracy: 0.9837 - val_loss: 0.1775 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.17706\n",
      "Epoch 56/500\n",
      "1040/1040 [==============================] - 0s 140us/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.1775 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.17706\n",
      "Epoch 57/500\n",
      "1040/1040 [==============================] - 0s 95us/step - loss: 0.0517 - accuracy: 0.9837 - val_loss: 0.1780 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.17706\n",
      "Epoch 58/500\n",
      "1040/1040 [==============================] - 0s 120us/step - loss: 0.0506 - accuracy: 0.9846 - val_loss: 0.1772 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.17706\n",
      "Epoch 59/500\n",
      "1040/1040 [==============================] - 0s 154us/step - loss: 0.0492 - accuracy: 0.9856 - val_loss: 0.1754 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.17706 to 0.17536, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 60/500\n",
      "1040/1040 [==============================] - 0s 194us/step - loss: 0.0490 - accuracy: 0.9856 - val_loss: 0.1738 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.17536 to 0.17383, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 61/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.0489 - accuracy: 0.9846 - val_loss: 0.1727 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.17383 to 0.17268, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 62/500\n",
      "1040/1040 [==============================] - 0s 155us/step - loss: 0.0488 - accuracy: 0.9846 - val_loss: 0.1718 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.17268 to 0.17182, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 63/500\n",
      "1040/1040 [==============================] - 0s 120us/step - loss: 0.0487 - accuracy: 0.9846 - val_loss: 0.1710 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.17182 to 0.17102, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 64/500\n",
      "1040/1040 [==============================] - 0s 112us/step - loss: 0.0486 - accuracy: 0.9846 - val_loss: 0.1702 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.17102 to 0.17025, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 65/500\n",
      "1040/1040 [==============================] - 0s 193us/step - loss: 0.0485 - accuracy: 0.9846 - val_loss: 0.1696 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.17025 to 0.16960, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 66/500\n",
      "1040/1040 [==============================] - 0s 86us/step - loss: 0.0484 - accuracy: 0.9846 - val_loss: 0.1691 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.16960 to 0.16911, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 67/500\n",
      "1040/1040 [==============================] - 0s 122us/step - loss: 0.0482 - accuracy: 0.9846 - val_loss: 0.1687 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.16911 to 0.16867, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 68/500\n",
      "1040/1040 [==============================] - 0s 120us/step - loss: 0.0481 - accuracy: 0.9846 - val_loss: 0.1683 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.16867 to 0.16830, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 69/500\n",
      "1040/1040 [==============================] - 0s 166us/step - loss: 0.0480 - accuracy: 0.9846 - val_loss: 0.1680 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.16830 to 0.16800, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 70/500\n",
      "1040/1040 [==============================] - 0s 135us/step - loss: 0.0479 - accuracy: 0.9846 - val_loss: 0.1677 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.16800 to 0.16773, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 71/500\n",
      "1040/1040 [==============================] - 0s 124us/step - loss: 0.0478 - accuracy: 0.9846 - val_loss: 0.1675 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.16773 to 0.16746, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 72/500\n",
      "1040/1040 [==============================] - 0s 135us/step - loss: 0.0477 - accuracy: 0.9856 - val_loss: 0.1672 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.16746 to 0.16724, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 73/500\n",
      "1040/1040 [==============================] - 0s 124us/step - loss: 0.0476 - accuracy: 0.9856 - val_loss: 0.1670 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.16724 to 0.16705, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 74/500\n",
      "1040/1040 [==============================] - 0s 152us/step - loss: 0.0474 - accuracy: 0.9856 - val_loss: 0.1668 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.16705 to 0.16683, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 75/500\n",
      "1040/1040 [==============================] - 0s 172us/step - loss: 0.0473 - accuracy: 0.9856 - val_loss: 0.1666 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.16683 to 0.16661, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 76/500\n",
      "1040/1040 [==============================] - 0s 109us/step - loss: 0.0472 - accuracy: 0.9856 - val_loss: 0.1665 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.16661 to 0.16645, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 77/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.0471 - accuracy: 0.9856 - val_loss: 0.1663 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.16645 to 0.16633, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 78/500\n",
      "1040/1040 [==============================] - 0s 130us/step - loss: 0.0470 - accuracy: 0.9856 - val_loss: 0.1662 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.16633 to 0.16621, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 79/500\n",
      "1040/1040 [==============================] - 0s 124us/step - loss: 0.0469 - accuracy: 0.9856 - val_loss: 0.1661 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.16621 to 0.16608, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 80/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.0468 - accuracy: 0.9856 - val_loss: 0.1660 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.16608 to 0.16596, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 81/500\n",
      "1040/1040 [==============================] - 0s 124us/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.1659 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.16596 to 0.16588, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 82/500\n",
      "1040/1040 [==============================] - 0s 76us/step - loss: 0.0465 - accuracy: 0.9856 - val_loss: 0.1658 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.16588 to 0.16578, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 83/500\n",
      "1040/1040 [==============================] - 0s 118us/step - loss: 0.0464 - accuracy: 0.9856 - val_loss: 0.1657 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.16578 to 0.16575, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 84/500\n",
      "1040/1040 [==============================] - 0s 110us/step - loss: 0.0463 - accuracy: 0.9856 - val_loss: 0.1657 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.16575 to 0.16570, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 85/500\n",
      "1040/1040 [==============================] - 0s 77us/step - loss: 0.0462 - accuracy: 0.9856 - val_loss: 0.1657 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.16570 to 0.16565, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 86/500\n",
      "1040/1040 [==============================] - 0s 181us/step - loss: 0.0461 - accuracy: 0.9856 - val_loss: 0.1656 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.16565 to 0.16560, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 87/500\n",
      "1040/1040 [==============================] - 0s 123us/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.16560 to 0.16554, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 88/500\n",
      "1040/1040 [==============================] - 0s 162us/step - loss: 0.0458 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.16554 to 0.16549, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 89/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.16549 to 0.16548, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 90/500\n",
      "1040/1040 [==============================] - 0s 116us/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.16548 to 0.16547, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 91/500\n",
      "1040/1040 [==============================] - 0s 155us/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.16547 to 0.16547, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 92/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.16547 to 0.16546, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 93/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.16546\n",
      "Epoch 94/500\n",
      "1040/1040 [==============================] - 0s 107us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.16546\n",
      "Epoch 95/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.16546\n",
      "Epoch 96/500\n",
      "1040/1040 [==============================] - 0s 144us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.16546 to 0.16546, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 97/500\n",
      "1040/1040 [==============================] - 0s 116us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.16546 to 0.16546, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 98/500\n",
      "1040/1040 [==============================] - 0s 146us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.16546 to 0.16546, saving model to ./210512_basic_freeze/model/base3_filter4_fold1_0512.h5\n",
      "Epoch 99/500\n",
      "1040/1040 [==============================] - 0s 123us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.16546\n",
      "Epoch 100/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.16546\n",
      "Epoch 101/500\n",
      "1040/1040 [==============================] - 0s 125us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.16546\n",
      "Epoch 102/500\n",
      "1040/1040 [==============================] - 0s 96us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.16546\n",
      "Epoch 103/500\n",
      "1040/1040 [==============================] - 0s 134us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.16546\n",
      "Epoch 104/500\n",
      "1040/1040 [==============================] - 0s 125us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.16546\n",
      "Epoch 105/500\n",
      "1040/1040 [==============================] - 0s 116us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.16546\n",
      "Epoch 106/500\n",
      "1040/1040 [==============================] - 0s 164us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.16546\n",
      "Epoch 107/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.16546\n",
      "Epoch 108/500\n",
      "1040/1040 [==============================] - 0s 148us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.16546\n",
      "Epoch 109/500\n",
      "1040/1040 [==============================] - 0s 163us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.16546\n",
      "Epoch 110/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.16546\n",
      "Epoch 111/500\n",
      "1040/1040 [==============================] - 0s 104us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.16546\n",
      "Epoch 112/500\n",
      "1040/1040 [==============================] - 0s 122us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.16546\n",
      "Epoch 113/500\n",
      "1040/1040 [==============================] - 0s 149us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.16546\n",
      "Epoch 114/500\n",
      "1040/1040 [==============================] - 0s 111us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.16546\n",
      "Epoch 115/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.16546\n",
      "Epoch 116/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.16546\n",
      "Epoch 117/500\n",
      "1040/1040 [==============================] - 0s 129us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.16546\n",
      "Epoch 118/500\n",
      "1040/1040 [==============================] - 0s 197us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.16546\n",
      "Epoch 119/500\n",
      "1040/1040 [==============================] - 0s 214us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.16546\n",
      "Epoch 120/500\n",
      "1040/1040 [==============================] - 0s 100us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.16546\n",
      "Epoch 121/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.16546\n",
      "Epoch 122/500\n",
      "1040/1040 [==============================] - 0s 124us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.16546\n",
      "Epoch 123/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.16546\n",
      "Epoch 124/500\n",
      "1040/1040 [==============================] - 0s 113us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.16546\n",
      "Epoch 125/500\n",
      "1040/1040 [==============================] - 0s 173us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.16546\n",
      "Epoch 126/500\n",
      "1040/1040 [==============================] - 0s 152us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.16546\n",
      "Epoch 127/500\n",
      "1040/1040 [==============================] - 0s 252us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.16546\n",
      "Epoch 128/500\n",
      "1040/1040 [==============================] - 0s 112us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.16546\n",
      "Epoch 129/500\n",
      "1040/1040 [==============================] - 0s 107us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.16546\n",
      "Epoch 130/500\n",
      "1040/1040 [==============================] - 0s 108us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.16546\n",
      "Epoch 131/500\n",
      "1040/1040 [==============================] - 0s 161us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.16546\n",
      "Epoch 132/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.16546\n",
      "Epoch 133/500\n",
      "1040/1040 [==============================] - 0s 105us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.16546\n",
      "Epoch 134/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.16546\n",
      "Epoch 135/500\n",
      "1040/1040 [==============================] - 0s 116us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.16546\n",
      "Epoch 136/500\n",
      "1040/1040 [==============================] - 0s 125us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.16546\n",
      "Epoch 137/500\n",
      "1040/1040 [==============================] - 0s 139us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.16546\n",
      "Epoch 138/500\n",
      "1040/1040 [==============================] - 0s 145us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.16546\n",
      "Epoch 139/500\n",
      "1040/1040 [==============================] - 0s 158us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.16546\n",
      "Epoch 140/500\n",
      "1040/1040 [==============================] - 0s 176us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.16546\n",
      "Epoch 141/500\n",
      "1040/1040 [==============================] - 0s 129us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.16546\n",
      "Epoch 142/500\n",
      "1040/1040 [==============================] - 0s 138us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.16546\n",
      "Epoch 143/500\n",
      "1040/1040 [==============================] - 0s 129us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.16546\n",
      "Epoch 144/500\n",
      "1040/1040 [==============================] - 0s 135us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.16546\n",
      "Epoch 145/500\n",
      "1040/1040 [==============================] - 0s 104us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.16546\n",
      "Epoch 146/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.16546\n",
      "Epoch 147/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.16546\n",
      "Epoch 148/500\n",
      "1040/1040 [==============================] - 0s 122us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.16546\n",
      "Epoch 149/500\n",
      "1040/1040 [==============================] - 0s 123us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.16546\n",
      "Epoch 150/500\n",
      "1040/1040 [==============================] - 0s 148us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.16546\n",
      "Epoch 151/500\n",
      "1040/1040 [==============================] - 0s 165us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.16546\n",
      "Epoch 152/500\n",
      "1040/1040 [==============================] - 0s 87us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.16546\n",
      "Epoch 153/500\n",
      "1040/1040 [==============================] - 0s 122us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.16546\n",
      "Epoch 154/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.16546\n",
      "Epoch 155/500\n",
      "1040/1040 [==============================] - 0s 112us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.16546\n",
      "Epoch 156/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.16546\n",
      "Epoch 157/500\n",
      "1040/1040 [==============================] - 0s 140us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.16546\n",
      "Epoch 158/500\n",
      "1040/1040 [==============================] - 0s 73us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.16546\n",
      "Epoch 159/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.16546\n",
      "Epoch 160/500\n",
      "1040/1040 [==============================] - 0s 118us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.16546\n",
      "Epoch 161/500\n",
      "1040/1040 [==============================] - 0s 112us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.16546\n",
      "Epoch 162/500\n",
      "1040/1040 [==============================] - 0s 144us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.16546\n",
      "Epoch 163/500\n",
      "1040/1040 [==============================] - 0s 160us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.16546\n",
      "Epoch 164/500\n",
      "1040/1040 [==============================] - 0s 105us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.16546\n",
      "Epoch 165/500\n",
      "1040/1040 [==============================] - 0s 146us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.16546\n",
      "Epoch 166/500\n",
      "1040/1040 [==============================] - 0s 91us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.16546\n",
      "Epoch 167/500\n",
      "1040/1040 [==============================] - 0s 129us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.16546\n",
      "Epoch 168/500\n",
      "1040/1040 [==============================] - 0s 118us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.16546\n",
      "Epoch 169/500\n",
      "1040/1040 [==============================] - 0s 119us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.16546\n",
      "Epoch 170/500\n",
      "1040/1040 [==============================] - 0s 144us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.16546\n",
      "Epoch 171/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.16546\n",
      "Epoch 172/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.16546\n",
      "Epoch 173/500\n",
      "1040/1040 [==============================] - 0s 187us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.16546\n",
      "Epoch 174/500\n",
      "1040/1040 [==============================] - 0s 153us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.16546\n",
      "Epoch 175/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.16546\n",
      "Epoch 176/500\n",
      "1040/1040 [==============================] - 0s 111us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.16546\n",
      "Epoch 177/500\n",
      "1040/1040 [==============================] - 0s 143us/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1655 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.16546\n",
      "Epoch 00177: early stopping\n",
      "TRAIN: 1299 TEST: 325\n",
      "0\n",
      "(?, 15, 15, 4)\n",
      "1\n",
      "(?, 15, 15, 4) 2 1 4\n",
      "(?, 15, 15, 8)\n",
      "8\n",
      "(?, 7, 7, 8)\n",
      "8\n",
      "4\n",
      "4\n",
      "2\n",
      "Train on 1040 samples, validate on 259 samples\n",
      "Epoch 1/500\n",
      "1040/1040 [==============================] - 1s 1ms/step - loss: 0.7600 - accuracy: 0.5096 - val_loss: 0.6992 - val_accuracy: 0.4749\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69924, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 2/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.5820 - accuracy: 0.7442 - val_loss: 0.6846 - val_accuracy: 0.5328\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69924 to 0.68461, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 3/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.4597 - accuracy: 0.8529 - val_loss: 0.6679 - val_accuracy: 0.5753\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.68461 to 0.66794, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 4/500\n",
      "1040/1040 [==============================] - 0s 173us/step - loss: 0.3728 - accuracy: 0.8923 - val_loss: 0.6683 - val_accuracy: 0.5598\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.66794\n",
      "Epoch 5/500\n",
      "1040/1040 [==============================] - 0s 164us/step - loss: 0.3070 - accuracy: 0.9125 - val_loss: 0.6792 - val_accuracy: 0.5560\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.66794\n",
      "Epoch 6/500\n",
      "1040/1040 [==============================] - 0s 92us/step - loss: 0.2583 - accuracy: 0.9221 - val_loss: 0.6967 - val_accuracy: 0.5521\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.66794\n",
      "Epoch 7/500\n",
      "1040/1040 [==============================] - 0s 133us/step - loss: 0.2249 - accuracy: 0.9337 - val_loss: 0.7101 - val_accuracy: 0.5521\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.66794\n",
      "Epoch 8/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.2015 - accuracy: 0.9385 - val_loss: 0.7155 - val_accuracy: 0.5676\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.66794\n",
      "Epoch 9/500\n",
      "1040/1040 [==============================] - 0s 110us/step - loss: 0.1850 - accuracy: 0.9423 - val_loss: 0.7075 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.66794\n",
      "Epoch 10/500\n",
      "1040/1040 [==============================] - 0s 119us/step - loss: 0.1727 - accuracy: 0.9471 - val_loss: 0.6865 - val_accuracy: 0.5907\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.66794\n",
      "Epoch 11/500\n",
      "1040/1040 [==============================] - 0s 161us/step - loss: 0.1630 - accuracy: 0.9490 - val_loss: 0.6616 - val_accuracy: 0.6178\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.66794 to 0.66158, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 12/500\n",
      "1040/1040 [==============================] - 0s 180us/step - loss: 0.1547 - accuracy: 0.9490 - val_loss: 0.6255 - val_accuracy: 0.6486\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.66158 to 0.62546, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 13/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.1475 - accuracy: 0.9519 - val_loss: 0.5793 - val_accuracy: 0.6988\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.62546 to 0.57934, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 14/500\n",
      "1040/1040 [==============================] - 0s 159us/step - loss: 0.1411 - accuracy: 0.9548 - val_loss: 0.5272 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.57934 to 0.52716, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 15/500\n",
      "1040/1040 [==============================] - 0s 104us/step - loss: 0.1354 - accuracy: 0.9587 - val_loss: 0.4759 - val_accuracy: 0.7683\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.52716 to 0.47588, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 16/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.1300 - accuracy: 0.9606 - val_loss: 0.4241 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.47588 to 0.42405, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 17/500\n",
      "1040/1040 [==============================] - 0s 132us/step - loss: 0.1249 - accuracy: 0.9615 - val_loss: 0.3795 - val_accuracy: 0.8456\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.42405 to 0.37954, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 18/500\n",
      "1040/1040 [==============================] - 0s 98us/step - loss: 0.1203 - accuracy: 0.9625 - val_loss: 0.3405 - val_accuracy: 0.8610\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.37954 to 0.34053, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 19/500\n",
      "1040/1040 [==============================] - 0s 116us/step - loss: 0.1159 - accuracy: 0.9615 - val_loss: 0.3050 - val_accuracy: 0.8919\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.34053 to 0.30503, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 20/500\n",
      "1040/1040 [==============================] - 0s 125us/step - loss: 0.1118 - accuracy: 0.9635 - val_loss: 0.2761 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.30503 to 0.27607, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 21/500\n",
      "1040/1040 [==============================] - 0s 78us/step - loss: 0.1080 - accuracy: 0.9644 - val_loss: 0.2537 - val_accuracy: 0.9112\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.27607 to 0.25372, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 22/500\n",
      "1040/1040 [==============================] - 0s 165us/step - loss: 0.1043 - accuracy: 0.9644 - val_loss: 0.2369 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.25372 to 0.23692, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 23/500\n",
      "1040/1040 [==============================] - 0s 131us/step - loss: 0.1008 - accuracy: 0.9654 - val_loss: 0.2228 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23692 to 0.22278, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 24/500\n",
      "1040/1040 [==============================] - 0s 130us/step - loss: 0.0975 - accuracy: 0.9654 - val_loss: 0.2139 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22278 to 0.21388, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 25/500\n",
      "1040/1040 [==============================] - 0s 108us/step - loss: 0.0941 - accuracy: 0.9663 - val_loss: 0.2074 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21388 to 0.20744, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 26/500\n",
      "1040/1040 [==============================] - 0s 113us/step - loss: 0.0907 - accuracy: 0.9673 - val_loss: 0.2003 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.20744 to 0.20028, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 27/500\n",
      "1040/1040 [==============================] - 0s 142us/step - loss: 0.0874 - accuracy: 0.9692 - val_loss: 0.1884 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20028 to 0.18837, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 28/500\n",
      "1040/1040 [==============================] - 0s 232us/step - loss: 0.0843 - accuracy: 0.9712 - val_loss: 0.1792 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.18837 to 0.17921, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 29/500\n",
      "1040/1040 [==============================] - 0s 112us/step - loss: 0.0813 - accuracy: 0.9712 - val_loss: 0.1682 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.17921 to 0.16821, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 30/500\n",
      "1040/1040 [==============================] - 0s 141us/step - loss: 0.0786 - accuracy: 0.9731 - val_loss: 0.1577 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.16821 to 0.15775, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 31/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.0758 - accuracy: 0.9731 - val_loss: 0.1499 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.15775 to 0.14991, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 32/500\n",
      "1040/1040 [==============================] - 0s 195us/step - loss: 0.0732 - accuracy: 0.9740 - val_loss: 0.1419 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.14991 to 0.14189, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 33/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.0706 - accuracy: 0.9760 - val_loss: 0.1345 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.14189 to 0.13446, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 34/500\n",
      "1040/1040 [==============================] - 0s 88us/step - loss: 0.0680 - accuracy: 0.9760 - val_loss: 0.1348 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.13446\n",
      "Epoch 35/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.0653 - accuracy: 0.9779 - val_loss: 0.1354 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.13446\n",
      "Epoch 36/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.0627 - accuracy: 0.9798 - val_loss: 0.1383 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.13446\n",
      "Epoch 37/500\n",
      "1040/1040 [==============================] - 0s 115us/step - loss: 0.0602 - accuracy: 0.9808 - val_loss: 0.1469 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.13446\n",
      "Epoch 38/500\n",
      "1040/1040 [==============================] - 0s 119us/step - loss: 0.0577 - accuracy: 0.9837 - val_loss: 0.1543 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.13446\n",
      "Epoch 39/500\n",
      "1040/1040 [==============================] - 0s 173us/step - loss: 0.0554 - accuracy: 0.9856 - val_loss: 0.1573 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.13446\n",
      "Epoch 40/500\n",
      "1040/1040 [==============================] - 0s 221us/step - loss: 0.0533 - accuracy: 0.9856 - val_loss: 0.1548 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.13446\n",
      "Epoch 41/500\n",
      "1040/1040 [==============================] - 0s 141us/step - loss: 0.0513 - accuracy: 0.9865 - val_loss: 0.1459 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.13446\n",
      "Epoch 42/500\n",
      "1040/1040 [==============================] - 0s 111us/step - loss: 0.0495 - accuracy: 0.9885 - val_loss: 0.1383 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.13446\n",
      "Epoch 43/500\n",
      "1040/1040 [==============================] - 0s 114us/step - loss: 0.0478 - accuracy: 0.9894 - val_loss: 0.1337 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.13446 to 0.13373, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 44/500\n",
      "1040/1040 [==============================] - 0s 136us/step - loss: 0.0464 - accuracy: 0.9894 - val_loss: 0.1269 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.13373 to 0.12687, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 45/500\n",
      "1040/1040 [==============================] - 0s 118us/step - loss: 0.0463 - accuracy: 0.9885 - val_loss: 0.1210 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.12687 to 0.12097, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 46/500\n",
      "1040/1040 [==============================] - 0s 207us/step - loss: 0.0461 - accuracy: 0.9885 - val_loss: 0.1155 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.12097 to 0.11552, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 47/500\n",
      "1040/1040 [==============================] - 0s 109us/step - loss: 0.0459 - accuracy: 0.9885 - val_loss: 0.1108 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.11552 to 0.11080, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 48/500\n",
      "1040/1040 [==============================] - 0s 116us/step - loss: 0.0458 - accuracy: 0.9885 - val_loss: 0.1067 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.11080 to 0.10674, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 49/500\n",
      "1040/1040 [==============================] - 0s 146us/step - loss: 0.0456 - accuracy: 0.9885 - val_loss: 0.1032 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.10674 to 0.10321, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 50/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.0455 - accuracy: 0.9885 - val_loss: 0.1003 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.10321 to 0.10029, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 51/500\n",
      "1040/1040 [==============================] - 0s 122us/step - loss: 0.0453 - accuracy: 0.9885 - val_loss: 0.0980 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.10029 to 0.09798, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 52/500\n",
      "1040/1040 [==============================] - 0s 135us/step - loss: 0.0452 - accuracy: 0.9885 - val_loss: 0.0960 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.09798 to 0.09605, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 53/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.0450 - accuracy: 0.9885 - val_loss: 0.0945 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.09605 to 0.09453, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 54/500\n",
      "1040/1040 [==============================] - 0s 135us/step - loss: 0.0449 - accuracy: 0.9894 - val_loss: 0.0933 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.09453 to 0.09330, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 55/500\n",
      "1040/1040 [==============================] - 0s 125us/step - loss: 0.0447 - accuracy: 0.9894 - val_loss: 0.0923 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.09330 to 0.09234, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 56/500\n",
      "1040/1040 [==============================] - 0s 97us/step - loss: 0.0446 - accuracy: 0.9894 - val_loss: 0.0916 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.09234 to 0.09157, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 57/500\n",
      "1040/1040 [==============================] - 0s 205us/step - loss: 0.0444 - accuracy: 0.9894 - val_loss: 0.0909 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.09157 to 0.09093, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 58/500\n",
      "1040/1040 [==============================] - 0s 108us/step - loss: 0.0443 - accuracy: 0.9894 - val_loss: 0.0904 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.09093 to 0.09044, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 59/500\n",
      "1040/1040 [==============================] - 0s 135us/step - loss: 0.0441 - accuracy: 0.9894 - val_loss: 0.0900 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09044 to 0.09005, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 60/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.0440 - accuracy: 0.9894 - val_loss: 0.0896 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.09005 to 0.08964, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 61/500\n",
      "1040/1040 [==============================] - 0s 183us/step - loss: 0.0438 - accuracy: 0.9894 - val_loss: 0.0893 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08964 to 0.08932, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 62/500\n",
      "1040/1040 [==============================] - 0s 131us/step - loss: 0.0437 - accuracy: 0.9894 - val_loss: 0.0890 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08932 to 0.08899, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 63/500\n",
      "1040/1040 [==============================] - 0s 102us/step - loss: 0.0435 - accuracy: 0.9894 - val_loss: 0.0887 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08899 to 0.08872, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 64/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.0434 - accuracy: 0.9894 - val_loss: 0.0885 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08872 to 0.08851, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 65/500\n",
      "1040/1040 [==============================] - 0s 147us/step - loss: 0.0432 - accuracy: 0.9894 - val_loss: 0.0884 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.08851 to 0.08838, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 66/500\n",
      "1040/1040 [==============================] - 0s 196us/step - loss: 0.0430 - accuracy: 0.9894 - val_loss: 0.0883 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08838 to 0.08827, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 67/500\n",
      "1040/1040 [==============================] - 0s 113us/step - loss: 0.0429 - accuracy: 0.9894 - val_loss: 0.0882 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08827 to 0.08821, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 68/500\n",
      "1040/1040 [==============================] - 0s 149us/step - loss: 0.0427 - accuracy: 0.9894 - val_loss: 0.0882 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.08821 to 0.08818, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 69/500\n",
      "1040/1040 [==============================] - 0s 120us/step - loss: 0.0426 - accuracy: 0.9894 - val_loss: 0.0881 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.08818 to 0.08811, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 70/500\n",
      "1040/1040 [==============================] - 0s 110us/step - loss: 0.0424 - accuracy: 0.9894 - val_loss: 0.0880 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.08811 to 0.08805, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 71/500\n",
      "1040/1040 [==============================] - 0s 191us/step - loss: 0.0423 - accuracy: 0.9894 - val_loss: 0.0880 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08805 to 0.08796, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 72/500\n",
      "1040/1040 [==============================] - 0s 104us/step - loss: 0.0421 - accuracy: 0.9894 - val_loss: 0.0879 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08796 to 0.08786, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 73/500\n",
      "1040/1040 [==============================] - 0s 119us/step - loss: 0.0420 - accuracy: 0.9894 - val_loss: 0.0877 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08786 to 0.08774, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 74/500\n",
      "1040/1040 [==============================] - 0s 116us/step - loss: 0.0418 - accuracy: 0.9894 - val_loss: 0.0876 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08774 to 0.08763, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 75/500\n",
      "1040/1040 [==============================] - 0s 82us/step - loss: 0.0417 - accuracy: 0.9894 - val_loss: 0.0875 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08763 to 0.08751, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 76/500\n",
      "1040/1040 [==============================] - 0s 190us/step - loss: 0.0415 - accuracy: 0.9894 - val_loss: 0.0874 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.08751 to 0.08737, saving model to ./210512_basic_freeze/model/base3_filter4_fold2_0512.h5\n",
      "Epoch 77/500\n",
      "1040/1040 [==============================] - 0s 113us/step - loss: 0.0414 - accuracy: 0.9894 - val_loss: 0.0877 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.08737\n",
      "Epoch 78/500\n",
      "1040/1040 [==============================] - 0s 119us/step - loss: 0.0414 - accuracy: 0.9894 - val_loss: 0.0881 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.08737\n",
      "Epoch 79/500\n",
      "1040/1040 [==============================] - 0s 141us/step - loss: 0.0414 - accuracy: 0.9894 - val_loss: 0.0885 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.08737\n",
      "Epoch 80/500\n",
      "1040/1040 [==============================] - 0s 90us/step - loss: 0.0413 - accuracy: 0.9894 - val_loss: 0.0889 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.08737\n",
      "Epoch 81/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.0413 - accuracy: 0.9894 - val_loss: 0.0892 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.08737\n",
      "Epoch 82/500\n",
      "1040/1040 [==============================] - 0s 110us/step - loss: 0.0413 - accuracy: 0.9894 - val_loss: 0.0896 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.08737\n",
      "Epoch 83/500\n",
      "1040/1040 [==============================] - 0s 112us/step - loss: 0.0413 - accuracy: 0.9894 - val_loss: 0.0899 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.08737\n",
      "Epoch 84/500\n",
      "1040/1040 [==============================] - 0s 134us/step - loss: 0.0413 - accuracy: 0.9894 - val_loss: 0.0903 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.08737\n",
      "Epoch 85/500\n",
      "1040/1040 [==============================] - 0s 164us/step - loss: 0.0413 - accuracy: 0.9894 - val_loss: 0.0906 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.08737\n",
      "Epoch 86/500\n",
      "1040/1040 [==============================] - 0s 138us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0909 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.08737\n",
      "Epoch 87/500\n",
      "1040/1040 [==============================] - 0s 97us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0913 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.08737\n",
      "Epoch 88/500\n",
      "1040/1040 [==============================] - 0s 103us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0916 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.08737\n",
      "Epoch 89/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0920 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.08737\n",
      "Epoch 90/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0923 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.08737\n",
      "Epoch 91/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0926 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.08737\n",
      "Epoch 92/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0929 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.08737\n",
      "Epoch 93/500\n",
      "1040/1040 [==============================] - 0s 59us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0932 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.08737\n",
      "Epoch 94/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0935 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.08737\n",
      "Epoch 95/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0937 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.08737\n",
      "Epoch 96/500\n",
      "1040/1040 [==============================] - 0s 138us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0939 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.08737\n",
      "Epoch 97/500\n",
      "1040/1040 [==============================] - 0s 173us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0941 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.08737\n",
      "Epoch 98/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0943 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.08737\n",
      "Epoch 99/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0945 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.08737\n",
      "Epoch 100/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0947 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.08737\n",
      "Epoch 101/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0949 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.08737\n",
      "Epoch 102/500\n",
      "1040/1040 [==============================] - 0s 60us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0950 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.08737\n",
      "Epoch 103/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0951 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.08737\n",
      "Epoch 104/500\n",
      "1040/1040 [==============================] - 0s 59us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0953 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.08737\n",
      "Epoch 105/500\n",
      "1040/1040 [==============================] - 0s 62us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0954 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.08737\n",
      "Epoch 106/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0955 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.08737\n",
      "Epoch 107/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0956 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.08737\n",
      "Epoch 108/500\n",
      "1040/1040 [==============================] - 0s 150us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0957 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.08737\n",
      "Epoch 109/500\n",
      "1040/1040 [==============================] - 0s 104us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0957 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.08737\n",
      "Epoch 110/500\n",
      "1040/1040 [==============================] - 0s 74us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0958 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.08737\n",
      "Epoch 111/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0959 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.08737\n",
      "Epoch 112/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0959 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.08737\n",
      "Epoch 113/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0960 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.08737\n",
      "Epoch 114/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0960 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.08737\n",
      "Epoch 115/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0961 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.08737\n",
      "Epoch 116/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0961 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.08737\n",
      "Epoch 117/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0962 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.08737\n",
      "Epoch 118/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0962 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.08737\n",
      "Epoch 119/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0962 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.08737\n",
      "Epoch 120/500\n",
      "1040/1040 [==============================] - 0s 143us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0963 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.08737\n",
      "Epoch 121/500\n",
      "1040/1040 [==============================] - 0s 169us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0963 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.08737\n",
      "Epoch 122/500\n",
      "1040/1040 [==============================] - 0s 79us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0963 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.08737\n",
      "Epoch 123/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0964 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.08737\n",
      "Epoch 124/500\n",
      "1040/1040 [==============================] - 0s 73us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0964 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.08737\n",
      "Epoch 125/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0964 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.08737\n",
      "Epoch 126/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0964 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.08737\n",
      "Epoch 127/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0964 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.08737\n",
      "Epoch 128/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0964 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.08737\n",
      "Epoch 129/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0965 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.08737\n",
      "Epoch 130/500\n",
      "1040/1040 [==============================] - 0s 106us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0965 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.08737\n",
      "Epoch 131/500\n",
      "1040/1040 [==============================] - 0s 159us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0965 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.08737\n",
      "Epoch 132/500\n",
      "1040/1040 [==============================] - 0s 130us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0965 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.08737\n",
      "Epoch 133/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0965 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.08737\n",
      "Epoch 134/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0965 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.08737\n",
      "Epoch 135/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0965 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.08737\n",
      "Epoch 136/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0965 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.08737\n",
      "Epoch 137/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0965 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.08737\n",
      "Epoch 138/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0965 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.08737\n",
      "Epoch 139/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0965 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.08737\n",
      "Epoch 140/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0966 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.08737\n",
      "Epoch 141/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0966 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.08737\n",
      "Epoch 142/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0966 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.08737\n",
      "Epoch 143/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0966 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.08737\n",
      "Epoch 144/500\n",
      "1040/1040 [==============================] - 0s 152us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0966 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.08737\n",
      "Epoch 145/500\n",
      "1040/1040 [==============================] - 0s 108us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0966 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.08737\n",
      "Epoch 146/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0966 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.08737\n",
      "Epoch 147/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0966 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.08737\n",
      "Epoch 148/500\n",
      "1040/1040 [==============================] - 0s 62us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0966 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.08737\n",
      "Epoch 149/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0966 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.08737\n",
      "Epoch 150/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0966 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.08737\n",
      "Epoch 151/500\n",
      "1040/1040 [==============================] - 0s 59us/step - loss: 0.0412 - accuracy: 0.9894 - val_loss: 0.0966 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.08737\n",
      "Epoch 00151: early stopping\n",
      "TRAIN: 1299 TEST: 325\n",
      "0\n",
      "(?, 15, 15, 4)\n",
      "1\n",
      "(?, 15, 15, 4) 2 1 4\n",
      "(?, 15, 15, 8)\n",
      "8\n",
      "(?, 7, 7, 8)\n",
      "8\n",
      "4\n",
      "4\n",
      "2\n",
      "Train on 1040 samples, validate on 259 samples\n",
      "Epoch 1/500\n",
      "1040/1040 [==============================] - 1s 798us/step - loss: 0.7148 - accuracy: 0.5452 - val_loss: 2.5302 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.53019, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 2/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.5740 - accuracy: 0.7596 - val_loss: 2.4001 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.53019 to 2.40009, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 3/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.4748 - accuracy: 0.8317 - val_loss: 2.3303 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.40009 to 2.33025, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 4/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.4018 - accuracy: 0.8692 - val_loss: 2.0457 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.33025 to 2.04566, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 5/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.3470 - accuracy: 0.8885 - val_loss: 1.6955 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.04566 to 1.69549, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 6/500\n",
      "1040/1040 [==============================] - 0s 145us/step - loss: 0.3067 - accuracy: 0.9010 - val_loss: 1.4002 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.69549 to 1.40019, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 7/500\n",
      "1040/1040 [==============================] - 0s 159us/step - loss: 0.2770 - accuracy: 0.9058 - val_loss: 1.2013 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.40019 to 1.20135, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 8/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.2547 - accuracy: 0.9115 - val_loss: 1.0638 - val_accuracy: 0.5058\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.20135 to 1.06379, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 9/500\n",
      "1040/1040 [==============================] - 0s 71us/step - loss: 0.2376 - accuracy: 0.9183 - val_loss: 0.9338 - val_accuracy: 0.5174\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.06379 to 0.93378, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 10/500\n",
      "1040/1040 [==============================] - 0s 70us/step - loss: 0.2240 - accuracy: 0.9221 - val_loss: 0.8018 - val_accuracy: 0.5444\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.93378 to 0.80175, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 11/500\n",
      "1040/1040 [==============================] - 0s 141us/step - loss: 0.2128 - accuracy: 0.9250 - val_loss: 0.7009 - val_accuracy: 0.5985\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.80175 to 0.70088, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 12/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.2033 - accuracy: 0.9279 - val_loss: 0.6303 - val_accuracy: 0.6448\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.70088 to 0.63029, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 13/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.1950 - accuracy: 0.9308 - val_loss: 0.5587 - val_accuracy: 0.6950\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.63029 to 0.55875, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 14/500\n",
      "1040/1040 [==============================] - 0s 74us/step - loss: 0.1869 - accuracy: 0.9337 - val_loss: 0.4941 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.55875 to 0.49408, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 15/500\n",
      "1040/1040 [==============================] - 0s 72us/step - loss: 0.1799 - accuracy: 0.9365 - val_loss: 0.4483 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.49408 to 0.44831, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 16/500\n",
      "1040/1040 [==============================] - 0s 182us/step - loss: 0.1736 - accuracy: 0.9413 - val_loss: 0.4031 - val_accuracy: 0.8263\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.44831 to 0.40315, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 17/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.1675 - accuracy: 0.9442 - val_loss: 0.3558 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.40315 to 0.35577, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 18/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.1620 - accuracy: 0.9452 - val_loss: 0.3188 - val_accuracy: 0.8842\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.35577 to 0.31879, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 19/500\n",
      "1040/1040 [==============================] - 0s 73us/step - loss: 0.1570 - accuracy: 0.9471 - val_loss: 0.2909 - val_accuracy: 0.8880\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.31879 to 0.29092, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 20/500\n",
      "1040/1040 [==============================] - 0s 84us/step - loss: 0.1524 - accuracy: 0.9490 - val_loss: 0.2705 - val_accuracy: 0.9035\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.29092 to 0.27053, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 21/500\n",
      "1040/1040 [==============================] - 0s 151us/step - loss: 0.1481 - accuracy: 0.9510 - val_loss: 0.2525 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.27053 to 0.25254, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 22/500\n",
      "1040/1040 [==============================] - 0s 74us/step - loss: 0.1442 - accuracy: 0.9519 - val_loss: 0.2361 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.25254 to 0.23609, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 23/500\n",
      "1040/1040 [==============================] - 0s 68us/step - loss: 0.1404 - accuracy: 0.9529 - val_loss: 0.2216 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23609 to 0.22164, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 24/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.1368 - accuracy: 0.9538 - val_loss: 0.2093 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22164 to 0.20929, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 25/500\n",
      "1040/1040 [==============================] - 0s 147us/step - loss: 0.1335 - accuracy: 0.9548 - val_loss: 0.1990 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.20929 to 0.19904, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 26/500\n",
      "1040/1040 [==============================] - 0s 68us/step - loss: 0.1303 - accuracy: 0.9558 - val_loss: 0.1892 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.19904 to 0.18923, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 27/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.1274 - accuracy: 0.9558 - val_loss: 0.1800 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.18923 to 0.18004, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 28/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.1245 - accuracy: 0.9577 - val_loss: 0.1717 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.18004 to 0.17171, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 29/500\n",
      "1040/1040 [==============================] - 0s 74us/step - loss: 0.1218 - accuracy: 0.9587 - val_loss: 0.1648 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.17171 to 0.16475, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 30/500\n",
      "1040/1040 [==============================] - 0s 165us/step - loss: 0.1192 - accuracy: 0.9596 - val_loss: 0.1588 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.16475 to 0.15879, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 31/500\n",
      "1040/1040 [==============================] - 0s 78us/step - loss: 0.1166 - accuracy: 0.9606 - val_loss: 0.1534 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.15879 to 0.15342, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 32/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.1141 - accuracy: 0.9606 - val_loss: 0.1478 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.15342 to 0.14784, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 33/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.1116 - accuracy: 0.9615 - val_loss: 0.1432 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.14784 to 0.14316, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 34/500\n",
      "1040/1040 [==============================] - 0s 74us/step - loss: 0.1093 - accuracy: 0.9625 - val_loss: 0.1396 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.14316 to 0.13965, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 35/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.1071 - accuracy: 0.9644 - val_loss: 0.1360 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.13965 to 0.13602, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 36/500\n",
      "1040/1040 [==============================] - 0s 156us/step - loss: 0.1050 - accuracy: 0.9644 - val_loss: 0.1329 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.13602 to 0.13290, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 37/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.1030 - accuracy: 0.9654 - val_loss: 0.1305 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.13290 to 0.13051, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 38/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.1010 - accuracy: 0.9654 - val_loss: 0.1286 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.13051 to 0.12862, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 39/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0991 - accuracy: 0.9673 - val_loss: 0.1265 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.12862 to 0.12652, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 40/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0973 - accuracy: 0.9683 - val_loss: 0.1244 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.12652 to 0.12435, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 41/500\n",
      "1040/1040 [==============================] - 0s 62us/step - loss: 0.0955 - accuracy: 0.9692 - val_loss: 0.1226 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.12435 to 0.12259, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 42/500\n",
      "1040/1040 [==============================] - 0s 134us/step - loss: 0.0937 - accuracy: 0.9712 - val_loss: 0.1214 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.12259 to 0.12137, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 43/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0919 - accuracy: 0.9712 - val_loss: 0.1200 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.12137 to 0.11998, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 44/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0902 - accuracy: 0.9721 - val_loss: 0.1186 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.11998 to 0.11862, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 45/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0884 - accuracy: 0.9721 - val_loss: 0.1174 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.11862 to 0.11741, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 46/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0866 - accuracy: 0.9721 - val_loss: 0.1164 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.11741 to 0.11644, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 47/500\n",
      "1040/1040 [==============================] - 0s 68us/step - loss: 0.0848 - accuracy: 0.9721 - val_loss: 0.1154 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.11644 to 0.11544, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 48/500\n",
      "1040/1040 [==============================] - 0s 174us/step - loss: 0.0831 - accuracy: 0.9721 - val_loss: 0.1145 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.11544 to 0.11449, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 49/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0814 - accuracy: 0.9721 - val_loss: 0.1138 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.11449 to 0.11382, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 50/500\n",
      "1040/1040 [==============================] - 0s 68us/step - loss: 0.0797 - accuracy: 0.9731 - val_loss: 0.1135 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.11382 to 0.11354, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 51/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0781 - accuracy: 0.9731 - val_loss: 0.1135 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.11354 to 0.11347, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 52/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0765 - accuracy: 0.9731 - val_loss: 0.1136 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.11347\n",
      "Epoch 53/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0751 - accuracy: 0.9731 - val_loss: 0.1136 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.11347\n",
      "Epoch 54/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0737 - accuracy: 0.9731 - val_loss: 0.1136 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.11347\n",
      "Epoch 55/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.0723 - accuracy: 0.9731 - val_loss: 0.1139 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.11347\n",
      "Epoch 56/500\n",
      "1040/1040 [==============================] - 0s 180us/step - loss: 0.0710 - accuracy: 0.9731 - val_loss: 0.1139 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.11347\n",
      "Epoch 57/500\n",
      "1040/1040 [==============================] - 0s 109us/step - loss: 0.0698 - accuracy: 0.9740 - val_loss: 0.1135 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.11347 to 0.11346, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 58/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0685 - accuracy: 0.9750 - val_loss: 0.1130 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.11346 to 0.11305, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 59/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0673 - accuracy: 0.9750 - val_loss: 0.1130 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.11305 to 0.11305, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 60/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0660 - accuracy: 0.9760 - val_loss: 0.1121 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.11305 to 0.11214, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 61/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0658 - accuracy: 0.9760 - val_loss: 0.1112 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.11214 to 0.11121, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 62/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0657 - accuracy: 0.9760 - val_loss: 0.1103 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.11121 to 0.11031, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 63/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0656 - accuracy: 0.9760 - val_loss: 0.1095 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.11031 to 0.10950, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 64/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0654 - accuracy: 0.9760 - val_loss: 0.1088 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.10950 to 0.10876, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 65/500\n",
      "1040/1040 [==============================] - 0s 179us/step - loss: 0.0653 - accuracy: 0.9760 - val_loss: 0.1081 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.10876 to 0.10806, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 66/500\n",
      "1040/1040 [==============================] - 0s 71us/step - loss: 0.0652 - accuracy: 0.9760 - val_loss: 0.1075 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.10806 to 0.10751, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 67/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0650 - accuracy: 0.9760 - val_loss: 0.1070 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.10751 to 0.10704, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 68/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0649 - accuracy: 0.9760 - val_loss: 0.1066 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.10704 to 0.10662, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 69/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0648 - accuracy: 0.9760 - val_loss: 0.1062 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.10662 to 0.10624, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 70/500\n",
      "1040/1040 [==============================] - 0s 105us/step - loss: 0.0647 - accuracy: 0.9760 - val_loss: 0.1059 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.10624 to 0.10592, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 71/500\n",
      "1040/1040 [==============================] - 0s 148us/step - loss: 0.0645 - accuracy: 0.9760 - val_loss: 0.1056 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.10592 to 0.10561, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 72/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0644 - accuracy: 0.9760 - val_loss: 0.1053 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.10561 to 0.10530, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 73/500\n",
      "1040/1040 [==============================] - 0s 62us/step - loss: 0.0643 - accuracy: 0.9760 - val_loss: 0.1050 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.10530 to 0.10496, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 74/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0641 - accuracy: 0.9760 - val_loss: 0.1046 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.10496 to 0.10465, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 75/500\n",
      "1040/1040 [==============================] - 0s 62us/step - loss: 0.0640 - accuracy: 0.9760 - val_loss: 0.1044 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.10465 to 0.10437, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 76/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0639 - accuracy: 0.9779 - val_loss: 0.1041 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.10437 to 0.10415, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 77/500\n",
      "1040/1040 [==============================] - 0s 149us/step - loss: 0.0637 - accuracy: 0.9779 - val_loss: 0.1039 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.10415 to 0.10392, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 78/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0636 - accuracy: 0.9779 - val_loss: 0.1037 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.10392 to 0.10373, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 79/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0635 - accuracy: 0.9779 - val_loss: 0.1035 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.10373 to 0.10355, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 80/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0634 - accuracy: 0.9779 - val_loss: 0.1034 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.10355 to 0.10341, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 81/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0632 - accuracy: 0.9779 - val_loss: 0.1033 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.10341 to 0.10327, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 82/500\n",
      "1040/1040 [==============================] - 0s 132us/step - loss: 0.0631 - accuracy: 0.9779 - val_loss: 0.1031 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.10327 to 0.10314, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 83/500\n",
      "1040/1040 [==============================] - 0s 86us/step - loss: 0.0630 - accuracy: 0.9779 - val_loss: 0.1030 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.10314 to 0.10302, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 84/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0629 - accuracy: 0.9779 - val_loss: 0.1029 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.10302 to 0.10291, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 85/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0627 - accuracy: 0.9779 - val_loss: 0.1028 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.10291 to 0.10280, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 86/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0626 - accuracy: 0.9779 - val_loss: 0.1027 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.10280 to 0.10269, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 87/500\n",
      "1040/1040 [==============================] - 0s 141us/step - loss: 0.0625 - accuracy: 0.9779 - val_loss: 0.1026 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.10269 to 0.10257, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 88/500\n",
      "1040/1040 [==============================] - 0s 104us/step - loss: 0.0624 - accuracy: 0.9779 - val_loss: 0.1025 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.10257 to 0.10247, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 89/500\n",
      "1040/1040 [==============================] - 0s 72us/step - loss: 0.0622 - accuracy: 0.9779 - val_loss: 0.1024 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.10247 to 0.10237, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 90/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0621 - accuracy: 0.9769 - val_loss: 0.1023 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.10237 to 0.10226, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 91/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0620 - accuracy: 0.9769 - val_loss: 0.1021 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.10226 to 0.10213, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 92/500\n",
      "1040/1040 [==============================] - 0s 158us/step - loss: 0.0619 - accuracy: 0.9769 - val_loss: 0.1020 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.10213 to 0.10204, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 93/500\n",
      "1040/1040 [==============================] - 0s 89us/step - loss: 0.0617 - accuracy: 0.9769 - val_loss: 0.1020 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.10204 to 0.10196, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 94/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0616 - accuracy: 0.9769 - val_loss: 0.1019 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.10196 to 0.10186, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 95/500\n",
      "1040/1040 [==============================] - 0s 61us/step - loss: 0.0615 - accuracy: 0.9769 - val_loss: 0.1018 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.10186 to 0.10177, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 96/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0614 - accuracy: 0.9769 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.10177 to 0.10168, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 97/500\n",
      "1040/1040 [==============================] - 0s 92us/step - loss: 0.0612 - accuracy: 0.9769 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.10168 to 0.10162, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 98/500\n",
      "1040/1040 [==============================] - 0s 159us/step - loss: 0.0611 - accuracy: 0.9769 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.10162 to 0.10155, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 99/500\n",
      "1040/1040 [==============================] - 0s 68us/step - loss: 0.0610 - accuracy: 0.9779 - val_loss: 0.1015 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.10155 to 0.10147, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 100/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0609 - accuracy: 0.9779 - val_loss: 0.1014 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.10147 to 0.10144, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 101/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0607 - accuracy: 0.9779 - val_loss: 0.1014 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.10144 to 0.10136, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 102/500\n",
      "1040/1040 [==============================] - 0s 68us/step - loss: 0.0606 - accuracy: 0.9779 - val_loss: 0.1013 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.10136 to 0.10128, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 103/500\n",
      "1040/1040 [==============================] - 0s 130us/step - loss: 0.0605 - accuracy: 0.9779 - val_loss: 0.1012 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.10128 to 0.10121, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 104/500\n",
      "1040/1040 [==============================] - 0s 82us/step - loss: 0.0604 - accuracy: 0.9788 - val_loss: 0.1012 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.10121 to 0.10116, saving model to ./210512_basic_freeze/model/base3_filter4_fold3_0512.h5\n",
      "Epoch 105/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.1012 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.10116\n",
      "Epoch 106/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.1012 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.10116\n",
      "Epoch 107/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.1012 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.10116\n",
      "Epoch 108/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.1012 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.10116\n",
      "Epoch 109/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.1013 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.10116\n",
      "Epoch 110/500\n",
      "1040/1040 [==============================] - 0s 103us/step - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.1013 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.10116\n",
      "Epoch 111/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.1013 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.10116\n",
      "Epoch 112/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.1013 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.10116\n",
      "Epoch 113/500\n",
      "1040/1040 [==============================] - 0s 70us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1014 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.10116\n",
      "Epoch 114/500\n",
      "1040/1040 [==============================] - 0s 72us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1014 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.10116\n",
      "Epoch 115/500\n",
      "1040/1040 [==============================] - 0s 68us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1014 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.10116\n",
      "Epoch 116/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1014 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.10116\n",
      "Epoch 117/500\n",
      "1040/1040 [==============================] - 0s 68us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1014 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.10116\n",
      "Epoch 118/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1015 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.10116\n",
      "Epoch 119/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1015 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.10116\n",
      "Epoch 120/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1015 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.10116\n",
      "Epoch 121/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1015 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.10116\n",
      "Epoch 122/500\n",
      "1040/1040 [==============================] - 0s 123us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1015 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.10116\n",
      "Epoch 123/500\n",
      "1040/1040 [==============================] - 0s 125us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1015 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.10116\n",
      "Epoch 124/500\n",
      "1040/1040 [==============================] - 0s 120us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1015 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.10116\n",
      "Epoch 125/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.10116\n",
      "Epoch 126/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.10116\n",
      "Epoch 127/500\n",
      "1040/1040 [==============================] - 0s 80us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.10116\n",
      "Epoch 128/500\n",
      "1040/1040 [==============================] - 0s 78us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.10116\n",
      "Epoch 129/500\n",
      "1040/1040 [==============================] - 0s 72us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.10116\n",
      "Epoch 130/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.10116\n",
      "Epoch 131/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.10116\n",
      "Epoch 132/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.10116\n",
      "Epoch 133/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.10116\n",
      "Epoch 134/500\n",
      "1040/1040 [==============================] - 0s 122us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.10116\n",
      "Epoch 135/500\n",
      "1040/1040 [==============================] - 0s 154us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.10116\n",
      "Epoch 136/500\n",
      "1040/1040 [==============================] - 0s 104us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.10116\n",
      "Epoch 137/500\n",
      "1040/1040 [==============================] - 0s 70us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.10116\n",
      "Epoch 138/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.10116\n",
      "Epoch 139/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.10116\n",
      "Epoch 140/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.10116\n",
      "Epoch 141/500\n",
      "1040/1040 [==============================] - 0s 62us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.10116\n",
      "Epoch 142/500\n",
      "1040/1040 [==============================] - 0s 72us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.10116\n",
      "Epoch 143/500\n",
      "1040/1040 [==============================] - 0s 76us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.10116\n",
      "Epoch 144/500\n",
      "1040/1040 [==============================] - 0s 129us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.10116\n",
      "Epoch 145/500\n",
      "1040/1040 [==============================] - 0s 155us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.10116\n",
      "Epoch 146/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.10116\n",
      "Epoch 147/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.10116\n",
      "Epoch 148/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.10116\n",
      "Epoch 149/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.10116\n",
      "Epoch 150/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.10116\n",
      "Epoch 151/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.10116\n",
      "Epoch 152/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.10116\n",
      "Epoch 153/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.10116\n",
      "Epoch 154/500\n",
      "1040/1040 [==============================] - 0s 83us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.10116\n",
      "Epoch 155/500\n",
      "1040/1040 [==============================] - 0s 105us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.10116\n",
      "Epoch 156/500\n",
      "1040/1040 [==============================] - 0s 109us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.10116\n",
      "Epoch 157/500\n",
      "1040/1040 [==============================] - 0s 100us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.10116\n",
      "Epoch 158/500\n",
      "1040/1040 [==============================] - 0s 79us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.10116\n",
      "Epoch 159/500\n",
      "1040/1040 [==============================] - 0s 70us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.10116\n",
      "Epoch 160/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.10116\n",
      "Epoch 161/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.10116\n",
      "Epoch 162/500\n",
      "1040/1040 [==============================] - 0s 62us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.10116\n",
      "Epoch 163/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.10116\n",
      "Epoch 164/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.10116\n",
      "Epoch 165/500\n",
      "1040/1040 [==============================] - 0s 68us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.10116\n",
      "Epoch 166/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.10116\n",
      "Epoch 167/500\n",
      "1040/1040 [==============================] - 0s 90us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.10116\n",
      "Epoch 168/500\n",
      "1040/1040 [==============================] - 0s 125us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.10116\n",
      "Epoch 169/500\n",
      "1040/1040 [==============================] - 0s 148us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.10116\n",
      "Epoch 170/500\n",
      "1040/1040 [==============================] - 0s 72us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.10116\n",
      "Epoch 171/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.10116\n",
      "Epoch 172/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.10116\n",
      "Epoch 173/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.10116\n",
      "Epoch 174/500\n",
      "1040/1040 [==============================] - 0s 70us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.10116\n",
      "Epoch 175/500\n",
      "1040/1040 [==============================] - 0s 68us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.10116\n",
      "Epoch 176/500\n",
      "1040/1040 [==============================] - 0s 62us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.10116\n",
      "Epoch 177/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.10116\n",
      "Epoch 178/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.10116\n",
      "Epoch 179/500\n",
      "1040/1040 [==============================] - 0s 144us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.10116\n",
      "Epoch 180/500\n",
      "1040/1040 [==============================] - 0s 134us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.10116\n",
      "Epoch 181/500\n",
      "1040/1040 [==============================] - 0s 99us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.10116\n",
      "Epoch 182/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.10116\n",
      "Epoch 183/500\n",
      "1040/1040 [==============================] - 0s 76us/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.1017 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.10116\n",
      "Epoch 00183: early stopping\n",
      "TRAIN: 1300 TEST: 324\n",
      "0\n",
      "(?, 15, 15, 4)\n",
      "1\n",
      "(?, 15, 15, 4) 2 1 4\n",
      "(?, 15, 15, 8)\n",
      "8\n",
      "(?, 7, 7, 8)\n",
      "8\n",
      "4\n",
      "4\n",
      "2\n",
      "Train on 1040 samples, validate on 260 samples\n",
      "Epoch 1/500\n",
      "1040/1040 [==============================] - 1s 785us/step - loss: 0.6774 - accuracy: 0.5288 - val_loss: 2.0808 - val_accuracy: 0.4962\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.08085, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 2/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.5584 - accuracy: 0.6894 - val_loss: 1.4853 - val_accuracy: 0.4962\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.08085 to 1.48526, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 3/500\n",
      "1040/1040 [==============================] - 0s 62us/step - loss: 0.4726 - accuracy: 0.8404 - val_loss: 1.2059 - val_accuracy: 0.4923\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.48526 to 1.20592, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 4/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.4024 - accuracy: 0.8942 - val_loss: 1.1024 - val_accuracy: 0.4923\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.20592 to 1.10240, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 5/500\n",
      "1040/1040 [==============================] - 0s 62us/step - loss: 0.3426 - accuracy: 0.9173 - val_loss: 1.1098 - val_accuracy: 0.4885\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.10240\n",
      "Epoch 6/500\n",
      "1040/1040 [==============================] - 0s 126us/step - loss: 0.2913 - accuracy: 0.9269 - val_loss: 1.1679 - val_accuracy: 0.4885\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.10240\n",
      "Epoch 7/500\n",
      "1040/1040 [==============================] - 0s 158us/step - loss: 0.2508 - accuracy: 0.9308 - val_loss: 1.1484 - val_accuracy: 0.4731\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.10240\n",
      "Epoch 8/500\n",
      "1040/1040 [==============================] - 0s 88us/step - loss: 0.2203 - accuracy: 0.9365 - val_loss: 1.0820 - val_accuracy: 0.4154\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.10240 to 1.08196, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 9/500\n",
      "1040/1040 [==============================] - 0s 80us/step - loss: 0.1973 - accuracy: 0.9423 - val_loss: 1.0069 - val_accuracy: 0.3462\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.08196 to 1.00686, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 10/500\n",
      "1040/1040 [==============================] - 0s 131us/step - loss: 0.1805 - accuracy: 0.9452 - val_loss: 0.9158 - val_accuracy: 0.3462\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.00686 to 0.91576, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 11/500\n",
      "1040/1040 [==============================] - 0s 73us/step - loss: 0.1672 - accuracy: 0.9452 - val_loss: 0.8322 - val_accuracy: 0.4923\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.91576 to 0.83218, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 12/500\n",
      "1040/1040 [==============================] - 0s 75us/step - loss: 0.1562 - accuracy: 0.9510 - val_loss: 0.7462 - val_accuracy: 0.5846\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.83218 to 0.74620, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 13/500\n",
      "1040/1040 [==============================] - 0s 137us/step - loss: 0.1473 - accuracy: 0.9529 - val_loss: 0.6601 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.74620 to 0.66014, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 14/500\n",
      "1040/1040 [==============================] - 0s 78us/step - loss: 0.1390 - accuracy: 0.9548 - val_loss: 0.5630 - val_accuracy: 0.7231\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.66014 to 0.56304, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 15/500\n",
      "1040/1040 [==============================] - 0s 129us/step - loss: 0.1313 - accuracy: 0.9577 - val_loss: 0.4608 - val_accuracy: 0.7538\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.56304 to 0.46078, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 16/500\n",
      "1040/1040 [==============================] - 0s 79us/step - loss: 0.1244 - accuracy: 0.9596 - val_loss: 0.3713 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.46078 to 0.37125, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 17/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.1181 - accuracy: 0.9615 - val_loss: 0.3000 - val_accuracy: 0.8923\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.37125 to 0.29998, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 18/500\n",
      "1040/1040 [==============================] - 0s 111us/step - loss: 0.1124 - accuracy: 0.9635 - val_loss: 0.2460 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.29998 to 0.24595, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 19/500\n",
      "1040/1040 [==============================] - 0s 123us/step - loss: 0.1074 - accuracy: 0.9673 - val_loss: 0.2118 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24595 to 0.21181, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 20/500\n",
      "1040/1040 [==============================] - 0s 75us/step - loss: 0.1029 - accuracy: 0.9702 - val_loss: 0.1883 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.21181 to 0.18827, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 21/500\n",
      "1040/1040 [==============================] - 0s 80us/step - loss: 0.0988 - accuracy: 0.9712 - val_loss: 0.1694 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.18827 to 0.16942, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 22/500\n",
      "1040/1040 [==============================] - 0s 70us/step - loss: 0.0950 - accuracy: 0.9721 - val_loss: 0.1532 - val_accuracy: 0.9346\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.16942 to 0.15317, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 23/500\n",
      "1040/1040 [==============================] - 0s 70us/step - loss: 0.0916 - accuracy: 0.9740 - val_loss: 0.1416 - val_accuracy: 0.9423\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.15317 to 0.14164, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 24/500\n",
      "1040/1040 [==============================] - 0s 176us/step - loss: 0.0884 - accuracy: 0.9769 - val_loss: 0.1333 - val_accuracy: 0.9462\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14164 to 0.13334, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 25/500\n",
      "1040/1040 [==============================] - 0s 79us/step - loss: 0.0855 - accuracy: 0.9779 - val_loss: 0.1286 - val_accuracy: 0.9500\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.13334 to 0.12855, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 26/500\n",
      "1040/1040 [==============================] - 0s 74us/step - loss: 0.0829 - accuracy: 0.9779 - val_loss: 0.1256 - val_accuracy: 0.9577\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.12855 to 0.12558, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 27/500\n",
      "1040/1040 [==============================] - 0s 71us/step - loss: 0.0804 - accuracy: 0.9779 - val_loss: 0.1244 - val_accuracy: 0.9577\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.12558 to 0.12444, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 28/500\n",
      "1040/1040 [==============================] - 0s 74us/step - loss: 0.0781 - accuracy: 0.9798 - val_loss: 0.1239 - val_accuracy: 0.9654\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.12444 to 0.12387, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 29/500\n",
      "1040/1040 [==============================] - 0s 122us/step - loss: 0.0760 - accuracy: 0.9788 - val_loss: 0.1241 - val_accuracy: 0.9654\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.12387\n",
      "Epoch 30/500\n",
      "1040/1040 [==============================] - 0s 140us/step - loss: 0.0740 - accuracy: 0.9788 - val_loss: 0.1251 - val_accuracy: 0.9654\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.12387\n",
      "Epoch 31/500\n",
      "1040/1040 [==============================] - 0s 70us/step - loss: 0.0722 - accuracy: 0.9788 - val_loss: 0.1285 - val_accuracy: 0.9577\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.12387\n",
      "Epoch 32/500\n",
      "1040/1040 [==============================] - 0s 135us/step - loss: 0.0706 - accuracy: 0.9779 - val_loss: 0.1324 - val_accuracy: 0.9577\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.12387\n",
      "Epoch 33/500\n",
      "1040/1040 [==============================] - 0s 89us/step - loss: 0.0689 - accuracy: 0.9788 - val_loss: 0.1322 - val_accuracy: 0.9615\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.12387\n",
      "Epoch 34/500\n",
      "1040/1040 [==============================] - 0s 77us/step - loss: 0.0674 - accuracy: 0.9788 - val_loss: 0.1319 - val_accuracy: 0.9615\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.12387\n",
      "Epoch 35/500\n",
      "1040/1040 [==============================] - 0s 75us/step - loss: 0.0660 - accuracy: 0.9808 - val_loss: 0.1336 - val_accuracy: 0.9577\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.12387\n",
      "Epoch 36/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0644 - accuracy: 0.9817 - val_loss: 0.1310 - val_accuracy: 0.9577\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.12387\n",
      "Epoch 37/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0631 - accuracy: 0.9808 - val_loss: 0.1294 - val_accuracy: 0.9577\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.12387\n",
      "Epoch 38/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0613 - accuracy: 0.9808 - val_loss: 0.1224 - val_accuracy: 0.9615\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.12387 to 0.12244, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 39/500\n",
      "1040/1040 [==============================] - 0s 72us/step - loss: 0.0612 - accuracy: 0.9808 - val_loss: 0.1155 - val_accuracy: 0.9615\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.12244 to 0.11551, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 40/500\n",
      "1040/1040 [==============================] - 0s 158us/step - loss: 0.0610 - accuracy: 0.9808 - val_loss: 0.1093 - val_accuracy: 0.9615\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.11551 to 0.10932, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 41/500\n",
      "1040/1040 [==============================] - 0s 128us/step - loss: 0.0609 - accuracy: 0.9808 - val_loss: 0.1041 - val_accuracy: 0.9615\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.10932 to 0.10412, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 42/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0607 - accuracy: 0.9808 - val_loss: 0.0999 - val_accuracy: 0.9654\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.10412 to 0.09986, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 43/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0606 - accuracy: 0.9808 - val_loss: 0.0960 - val_accuracy: 0.9654\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.09986 to 0.09604, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 44/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0604 - accuracy: 0.9808 - val_loss: 0.0927 - val_accuracy: 0.9654\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.09604 to 0.09270, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 45/500\n",
      "1040/1040 [==============================] - 0s 214us/step - loss: 0.0603 - accuracy: 0.9808 - val_loss: 0.0899 - val_accuracy: 0.9654\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.09270 to 0.08993, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 46/500\n",
      "1040/1040 [==============================] - 0s 75us/step - loss: 0.0602 - accuracy: 0.9808 - val_loss: 0.0874 - val_accuracy: 0.9654\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.08993 to 0.08742, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 47/500\n",
      "1040/1040 [==============================] - 0s 77us/step - loss: 0.0600 - accuracy: 0.9808 - val_loss: 0.0852 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.08742 to 0.08518, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 48/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0599 - accuracy: 0.9808 - val_loss: 0.0833 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.08518 to 0.08332, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 49/500\n",
      "1040/1040 [==============================] - 0s 109us/step - loss: 0.0597 - accuracy: 0.9808 - val_loss: 0.0818 - val_accuracy: 0.9731\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.08332 to 0.08185, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 50/500\n",
      "1040/1040 [==============================] - 0s 174us/step - loss: 0.0596 - accuracy: 0.9808 - val_loss: 0.0806 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.08185 to 0.08056, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 51/500\n",
      "1040/1040 [==============================] - 0s 83us/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.0793 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.08056 to 0.07933, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 52/500\n",
      "1040/1040 [==============================] - 0s 72us/step - loss: 0.0593 - accuracy: 0.9808 - val_loss: 0.0782 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.07933 to 0.07815, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 53/500\n",
      "1040/1040 [==============================] - 0s 78us/step - loss: 0.0592 - accuracy: 0.9808 - val_loss: 0.0771 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.07815 to 0.07710, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 54/500\n",
      "1040/1040 [==============================] - 0s 71us/step - loss: 0.0590 - accuracy: 0.9808 - val_loss: 0.0761 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.07710 to 0.07615, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 55/500\n",
      "1040/1040 [==============================] - 0s 109us/step - loss: 0.0589 - accuracy: 0.9808 - val_loss: 0.0753 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.07615 to 0.07533, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 56/500\n",
      "1040/1040 [==============================] - 0s 97us/step - loss: 0.0587 - accuracy: 0.9808 - val_loss: 0.0747 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.07533 to 0.07467, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 57/500\n",
      "1040/1040 [==============================] - 0s 103us/step - loss: 0.0586 - accuracy: 0.9808 - val_loss: 0.0742 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.07467 to 0.07415, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 58/500\n",
      "1040/1040 [==============================] - 0s 78us/step - loss: 0.0585 - accuracy: 0.9808 - val_loss: 0.0737 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.07415 to 0.07369, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 59/500\n",
      "1040/1040 [==============================] - 0s 79us/step - loss: 0.0583 - accuracy: 0.9808 - val_loss: 0.0732 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.07369 to 0.07321, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 60/500\n",
      "1040/1040 [==============================] - 0s 124us/step - loss: 0.0582 - accuracy: 0.9808 - val_loss: 0.0727 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.07321 to 0.07268, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 61/500\n",
      "1040/1040 [==============================] - 0s 82us/step - loss: 0.0580 - accuracy: 0.9808 - val_loss: 0.0722 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.07268 to 0.07217, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 62/500\n",
      "1040/1040 [==============================] - 0s 101us/step - loss: 0.0579 - accuracy: 0.9808 - val_loss: 0.0717 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.07217 to 0.07169, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 63/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.0578 - accuracy: 0.9808 - val_loss: 0.0713 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.07169 to 0.07127, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 64/500\n",
      "1040/1040 [==============================] - 0s 106us/step - loss: 0.0576 - accuracy: 0.9808 - val_loss: 0.0709 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07127 to 0.07090, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 65/500\n",
      "1040/1040 [==============================] - 0s 142us/step - loss: 0.0575 - accuracy: 0.9808 - val_loss: 0.0706 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.07090 to 0.07056, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 66/500\n",
      "1040/1040 [==============================] - 0s 83us/step - loss: 0.0574 - accuracy: 0.9808 - val_loss: 0.0702 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07056 to 0.07025, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 67/500\n",
      "1040/1040 [==============================] - 0s 76us/step - loss: 0.0572 - accuracy: 0.9808 - val_loss: 0.0700 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.07025 to 0.06997, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 68/500\n",
      "1040/1040 [==============================] - 0s 133us/step - loss: 0.0571 - accuracy: 0.9808 - val_loss: 0.0698 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.06997 to 0.06976, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 69/500\n",
      "1040/1040 [==============================] - 0s 143us/step - loss: 0.0569 - accuracy: 0.9808 - val_loss: 0.0696 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06976 to 0.06959, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 70/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0568 - accuracy: 0.9808 - val_loss: 0.0694 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06959 to 0.06940, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 71/500\n",
      "1040/1040 [==============================] - 0s 79us/step - loss: 0.0566 - accuracy: 0.9808 - val_loss: 0.0692 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06940 to 0.06924, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 72/500\n",
      "1040/1040 [==============================] - 0s 71us/step - loss: 0.0565 - accuracy: 0.9808 - val_loss: 0.0691 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.06924 to 0.06912, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 73/500\n",
      "1040/1040 [==============================] - 0s 70us/step - loss: 0.0564 - accuracy: 0.9808 - val_loss: 0.0690 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06912 to 0.06899, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 74/500\n",
      "1040/1040 [==============================] - 0s 160us/step - loss: 0.0562 - accuracy: 0.9808 - val_loss: 0.0689 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06899 to 0.06886, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 75/500\n",
      "1040/1040 [==============================] - 0s 80us/step - loss: 0.0561 - accuracy: 0.9808 - val_loss: 0.0688 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.06886 to 0.06876, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 76/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0559 - accuracy: 0.9808 - val_loss: 0.0687 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06876 to 0.06867, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 77/500\n",
      "1040/1040 [==============================] - 0s 73us/step - loss: 0.0558 - accuracy: 0.9808 - val_loss: 0.0686 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06867 to 0.06859, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 78/500\n",
      "1040/1040 [==============================] - 0s 89us/step - loss: 0.0556 - accuracy: 0.9808 - val_loss: 0.0685 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.06859 to 0.06852, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 79/500\n",
      "1040/1040 [==============================] - 0s 129us/step - loss: 0.0555 - accuracy: 0.9808 - val_loss: 0.0685 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.06852 to 0.06850, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 80/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0554 - accuracy: 0.9808 - val_loss: 0.0685 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.06850 to 0.06847, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 81/500\n",
      "1040/1040 [==============================] - 0s 71us/step - loss: 0.0552 - accuracy: 0.9808 - val_loss: 0.0684 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.06847 to 0.06841, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 82/500\n",
      "1040/1040 [==============================] - 0s 71us/step - loss: 0.0550 - accuracy: 0.9808 - val_loss: 0.0683 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06841 to 0.06830, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 83/500\n",
      "1040/1040 [==============================] - 0s 77us/step - loss: 0.0550 - accuracy: 0.9808 - val_loss: 0.0682 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06830 to 0.06821, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 84/500\n",
      "1040/1040 [==============================] - 0s 82us/step - loss: 0.0550 - accuracy: 0.9808 - val_loss: 0.0681 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.06821 to 0.06813, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 85/500\n",
      "1040/1040 [==============================] - 0s 170us/step - loss: 0.0550 - accuracy: 0.9808 - val_loss: 0.0681 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06813 to 0.06805, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 86/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0550 - accuracy: 0.9808 - val_loss: 0.0680 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.06805 to 0.06799, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 87/500\n",
      "1040/1040 [==============================] - 0s 72us/step - loss: 0.0550 - accuracy: 0.9808 - val_loss: 0.0679 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06799 to 0.06792, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 88/500\n",
      "1040/1040 [==============================] - 0s 77us/step - loss: 0.0550 - accuracy: 0.9808 - val_loss: 0.0679 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.06792 to 0.06786, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 89/500\n",
      "1040/1040 [==============================] - 0s 133us/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0678 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.06786 to 0.06781, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 90/500\n",
      "1040/1040 [==============================] - 0s 121us/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0678 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.06781 to 0.06776, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 91/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0677 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.06776 to 0.06771, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 92/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0677 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.06771 to 0.06767, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 93/500\n",
      "1040/1040 [==============================] - 0s 76us/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0676 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.06767 to 0.06764, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 94/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0676 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.06764 to 0.06760, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 95/500\n",
      "1040/1040 [==============================] - 0s 154us/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0676 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.06760 to 0.06757, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 96/500\n",
      "1040/1040 [==============================] - 0s 71us/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0675 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.06757 to 0.06754, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 97/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0675 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.06754 to 0.06752, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 98/500\n",
      "1040/1040 [==============================] - 0s 63us/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0675 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.06752 to 0.06750, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 99/500\n",
      "1040/1040 [==============================] - 0s 79us/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0675 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.06750 to 0.06748, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 100/500\n",
      "1040/1040 [==============================] - 0s 171us/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0675 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.06748 to 0.06746, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 101/500\n",
      "1040/1040 [==============================] - 0s 76us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0674 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.06746 to 0.06744, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 102/500\n",
      "1040/1040 [==============================] - 0s 74us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0674 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.06744 to 0.06743, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 103/500\n",
      "1040/1040 [==============================] - 0s 66us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0674 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.06743 to 0.06741, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 104/500\n",
      "1040/1040 [==============================] - 0s 68us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0674 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.06741 to 0.06740, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 105/500\n",
      "1040/1040 [==============================] - 0s 103us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0674 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.06740 to 0.06739, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 106/500\n",
      "1040/1040 [==============================] - 0s 157us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0674 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.06739 to 0.06738, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 107/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0674 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.06738 to 0.06737, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 108/500\n",
      "1040/1040 [==============================] - 0s 70us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0674 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.06737 to 0.06736, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 109/500\n",
      "1040/1040 [==============================] - 0s 78us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0674 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.06736 to 0.06736, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 110/500\n",
      "1040/1040 [==============================] - 0s 148us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0674 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.06736 to 0.06735, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 111/500\n",
      "1040/1040 [==============================] - 0s 129us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.06735 to 0.06734, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 112/500\n",
      "1040/1040 [==============================] - 0s 75us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.06734 to 0.06734, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 113/500\n",
      "1040/1040 [==============================] - 0s 64us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.06734 to 0.06733, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 114/500\n",
      "1040/1040 [==============================] - 0s 75us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.06733 to 0.06733, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 115/500\n",
      "1040/1040 [==============================] - 0s 79us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.06733 to 0.06733, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 116/500\n",
      "1040/1040 [==============================] - 0s 155us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.06733 to 0.06732, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 117/500\n",
      "1040/1040 [==============================] - 0s 79us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.06732 to 0.06732, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 118/500\n",
      "1040/1040 [==============================] - 0s 67us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.06732 to 0.06731, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 119/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.06731 to 0.06731, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 120/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.06731 to 0.06731, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 121/500\n",
      "1040/1040 [==============================] - 0s 183us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.06731 to 0.06731, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 122/500\n",
      "1040/1040 [==============================] - 0s 75us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.06731 to 0.06730, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 123/500\n",
      "1040/1040 [==============================] - 0s 88us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.06730 to 0.06730, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 124/500\n",
      "1040/1040 [==============================] - 0s 90us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.06730 to 0.06730, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 125/500\n",
      "1040/1040 [==============================] - 0s 73us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.06730 to 0.06730, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 126/500\n",
      "1040/1040 [==============================] - 0s 142us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.06730 to 0.06730, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 127/500\n",
      "1040/1040 [==============================] - 0s 147us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.06730 to 0.06730, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 128/500\n",
      "1040/1040 [==============================] - 0s 131us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.06730 to 0.06730, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 129/500\n",
      "1040/1040 [==============================] - 0s 78us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.06730 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 130/500\n",
      "1040/1040 [==============================] - 0s 175us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 131/500\n",
      "1040/1040 [==============================] - 0s 70us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 132/500\n",
      "1040/1040 [==============================] - 0s 242us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 133/500\n",
      "1040/1040 [==============================] - 0s 91us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 134/500\n",
      "1040/1040 [==============================] - 0s 139us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 135/500\n",
      "1040/1040 [==============================] - 0s 76us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 136/500\n",
      "1040/1040 [==============================] - 0s 142us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 137/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 138/500\n",
      "1040/1040 [==============================] - 0s 189us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 139/500\n",
      "1040/1040 [==============================] - 0s 75us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 140/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 141/500\n",
      "1040/1040 [==============================] - 0s 112us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 142/500\n",
      "1040/1040 [==============================] - 0s 73us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 143/500\n",
      "1040/1040 [==============================] - 0s 103us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 144/500\n",
      "1040/1040 [==============================] - 0s 135us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 145/500\n",
      "1040/1040 [==============================] - 0s 106us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 146/500\n",
      "1040/1040 [==============================] - 0s 65us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 147/500\n",
      "1040/1040 [==============================] - 0s 150us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 148/500\n",
      "1040/1040 [==============================] - 0s 79us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 149/500\n",
      "1040/1040 [==============================] - 0s 89us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 150/500\n",
      "1040/1040 [==============================] - 0s 198us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 151/500\n",
      "1040/1040 [==============================] - 0s 146us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 152/500\n",
      "1040/1040 [==============================] - 0s 71us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 153/500\n",
      "1040/1040 [==============================] - 0s 69us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 154/500\n",
      "1040/1040 [==============================] - 0s 139us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.06729 to 0.06729, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 155/500\n",
      "1040/1040 [==============================] - 0s 166us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.06729 to 0.06728, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 156/500\n",
      "1040/1040 [==============================] - 0s 143us/step - loss: 0.0548 - accuracy: 0.9808 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.06728 to 0.06728, saving model to ./210512_basic_freeze/model/base3_filter4_fold4_0512.h5\n",
      "Epoch 00156: early stopping\n"
     ]
    }
   ],
   "source": [
    "savepath='./210512_basic_freeze'\n",
    "os.makedirs(savepath+'/npy', exist_ok=True)\n",
    "os.makedirs(savepath+'/result', exist_ok=True)\n",
    "os.makedirs(savepath+'/model', exist_ok=True)\n",
    "i=0\n",
    "performances = np.ndarray((k,4), dtype=np.float32)\n",
    "\n",
    "for train_index, test_index in skf.split(data_x,data_y):\n",
    "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "#     indexs = np.concatenate((train_index, test_index), axis= 0)\n",
    "#     train_index = indexs[:1300]\n",
    "#     test_index = indexs[1300:]\n",
    "#     print(\"RETRAIN:\", len(train_index), \"RETEST:\", len(test_index))\n",
    "    dtrain_x, test_x = data_x[train_index], data_x[test_index]\n",
    "    dtrain_y, test_y = data_y[train_index], data_y[test_index]\n",
    "    \n",
    "    np.save(savepath+'/npy/test_x_fold{}.npy'.format(str(i)), test_x)\n",
    "    np.save(savepath+'/npy/test_y_fold{}.npy'.format(str(i)), test_y)\n",
    "    np.save(savepath+'/npy/train_x_fold{}.npy'.format(str(i)), train_x)\n",
    "    np.save(savepath+'/npy/train_y_fold{}.npy'.format(str(i)), train_y)\n",
    "    \n",
    "    train_x,val_x,train_y,val_y = train_test_split(dtrain_x,dtrain_y, stratify = dtrain_y, train_size=1040)\n",
    "\n",
    "    input_img = Input(shape=(32,32,1))\n",
    "    model = base_classification_jw(input_img, filters = 4, scale = 2)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath=savepath+'/model/base3_filter4_fold{}_0512.h5'.format(str(i)), verbose=1, save_best_only=True, monitor='val_loss')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                  patience=10, min_lr=0, min_delta=0.001, verbose=1)\n",
    "    earlystopper = EarlyStopping(patience=30, verbose=1, monitor='loss')\n",
    "    callbacks_list = [reduce_lr, checkpointer, earlystopper]\n",
    "    \n",
    "    results = model.fit(train_x, train_y, batch_size=128, epochs=500, verbose=1, validation_data=(val_x, val_y), shuffle=False, callbacks=callbacks_list)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "325/325 [==============================] - 1s 2ms/step\n",
      "135 27 158 5\n",
      "###########RESULT########\n",
      "AUC:0.979, SEN:0.964, SPEC:0.854, ACC:0.902, PREC:135.0\n",
      "TP:135, FP:27. TN:158, FN:5\n",
      "#########################\n",
      "1\n",
      "325/325 [==============================] - 0s 1ms/step\n",
      "152 10 163 0\n",
      "###########RESULT########\n",
      "AUC:0.997, SEN:1.0, SPEC:0.942, ACC:0.969, PREC:152.0\n",
      "TP:152, FP:10. TN:163, FN:0\n",
      "#########################\n",
      "2\n",
      "325/325 [==============================] - 1s 2ms/step\n",
      "152 11 147 15\n",
      "###########RESULT########\n",
      "AUC:0.962, SEN:0.91, SPEC:0.93, ACC:0.92, PREC:152.0\n",
      "TP:152, FP:11. TN:147, FN:15\n",
      "#########################\n",
      "3\n",
      "325/325 [==============================] - 1s 3ms/step\n",
      "159 4 161 1\n",
      "###########RESULT########\n",
      "AUC:1.0, SEN:0.994, SPEC:0.976, ACC:0.985, PREC:159.0\n",
      "TP:159, FP:4. TN:161, FN:1\n",
      "#########################\n",
      "4\n",
      "324/324 [==============================] - 1s 3ms/step\n",
      "160 2 138 24\n",
      "###########RESULT########\n",
      "AUC:0.994, SEN:0.87, SPEC:0.986, ACC:0.92, PREC:160.0\n",
      "TP:160, FP:2. TN:138, FN:24\n",
      "#########################\n"
     ]
    }
   ],
   "source": [
    "# check model and save result\n",
    "i=0\n",
    "performances = np.ndarray((k,4), dtype=np.float32)\n",
    "for i in range(k):\n",
    "    print(i)\n",
    "    test_model = load_model(savepath+'/model/base3_filter4_fold{}_0512.h5'.format(str(i)))\n",
    "    test_x= np.load(savepath+'/npy/test_x_fold{}.npy'.format(str(i)))\n",
    "    test_y= np.load(savepath+'/npy/test_y_fold{}.npy'.format(str(i)))\n",
    "    test_result= test_model.predict(test_x, batch_size=128, verbose=1)\n",
    "    np.save(savepath+'/npy/test_result_fold{}.npy'.format(str(i)), test_result)\n",
    "    fpr_res,tpr_res,_=roc_curve(test_y,test_result)\n",
    "    auc_res=auc(fpr_res, tpr_res)\n",
    "    #     print(\"loss: %.2f, 정확도: %.3f  \" %(score[0], score[1]))\n",
    "    res_tp, res_fp, res_tn, res_fn, res_sensitivity, res_specificity, acc, prec= calculate_performance(test_result, test_y)\n",
    "    \n",
    "    performanceList = [auc_res, res_sensitivity, res_specificity, acc]\n",
    "    for a in range(4):\n",
    "        performances[i][a] = performanceList[a]\n",
    "    \n",
    "#     interp_tpr = np.interp(mean_fpr, _, _)\n",
    "#     interp_tpr[0] = 0.0\n",
    "#     tprs.append(interp_tpr)\n",
    "#     np.save('./210512/npy/performanceList_fold{}.npy'.format(str(i)), performances)\n",
    "    print('###########RESULT########')\n",
    "    print('AUC:{}, SEN:{}, SPEC:{}, ACC:{}, PREC:{}'.format(round(auc_res,3),round(res_sensitivity,3),round(res_specificity,3),round(acc,3),round(prec,3)))\n",
    "    print('TP:{}, FP:{}. TN:{}, FN:{}'.format(res_tp, res_fp, res_tn, res_fn))\n",
    "    print('#########################')\n",
    "    i=+1\n",
    "np.save(savepath+'/npy/performanceList.npy', performances)\n",
    "all_perform = pd.DataFrame(performances)\n",
    "all_perform.to_csv(savepath+'/result/all_perform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "135 27 158 5\n",
      "###########RESULT########\n",
      "AUC:0.979, SEN:0.964, SPEC:0.854, ACC:0.902, PREC:135.0\n",
      "TP:135, FP:27. TN:158, FN:5\n",
      "#########################\n",
      "1\n",
      "152 10 163 0\n",
      "###########RESULT########\n",
      "AUC:0.997, SEN:1.0, SPEC:0.942, ACC:0.969, PREC:152.0\n",
      "TP:152, FP:10. TN:163, FN:0\n",
      "#########################\n",
      "2\n",
      "152 11 147 15\n",
      "###########RESULT########\n",
      "AUC:0.962, SEN:0.91, SPEC:0.93, ACC:0.92, PREC:152.0\n",
      "TP:152, FP:11. TN:147, FN:15\n",
      "#########################\n",
      "3\n",
      "159 4 161 1\n",
      "###########RESULT########\n",
      "AUC:1.0, SEN:0.994, SPEC:0.976, ACC:0.985, PREC:159.0\n",
      "TP:159, FP:4. TN:161, FN:1\n",
      "#########################\n",
      "4\n",
      "160 2 138 24\n",
      "###########RESULT########\n",
      "AUC:0.994, SEN:0.87, SPEC:0.986, ACC:0.92, PREC:160.0\n",
      "TP:160, FP:2. TN:138, FN:24\n",
      "#########################\n",
      "[0.9938271604938271, 0.8695652882797347, 0.98571429591836, 0.9197531111873114]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "# performances = np.ndarray((k,4), dtype=np.float32)\n",
    "for i in range(k):\n",
    "    print(i)\n",
    "#     test_model = load_model(savepath+'/model/residual3_filter4_fold{}_0512.h5'.format(str(i)))\n",
    "    test_x= np.load(savepath+'/npy/test_x_fold{}.npy'.format(str(i)))\n",
    "    test_y= np.load(savepath+'/npy/test_y_fold{}.npy'.format(str(i)))\n",
    "    test_result= np.load(savepath+'/npy/test_result_fold{}.npy'.format(str(i)))\n",
    "#     np.save(savepath+'/npy/test_result_fold{}.npy'.format(str(i)), test_result)\n",
    "    fpr_res,tpr_res,_=roc_curve(test_y,test_result)\n",
    "    auc_res=auc(fpr_res, tpr_res)\n",
    "    #     print(\"loss: %.2f, 정확도: %.3f  \" %(score[0], score[1]))\n",
    "    res_tp, res_fp, res_tn, res_fn, res_sensitivity, res_specificity, acc, prec= calculate_performance(test_result, test_y)\n",
    "    \n",
    "    performanceList = [auc_res, res_sensitivity, res_specificity, acc]\n",
    "    for a in range(4):\n",
    "        performances[i][a] = performanceList[a]\n",
    "    \n",
    "#     interp_tpr = np.interp(mean_fpr, _, _)\n",
    "#     interp_tpr[0] = 0.0\n",
    "#     tprs.append(interp_tpr)\n",
    "#     np.save('./210512/npy/performanceList_fold{}.npy'.format(str(i)), performances)\n",
    "    print('###########RESULT########')\n",
    "    print('AUC:{}, SEN:{}, SPEC:{}, ACC:{}, PREC:{}'.format(round(auc_res,3),round(res_sensitivity,3),round(res_specificity,3),round(acc,3),round(prec,3)))\n",
    "    print('TP:{}, FP:{}. TN:{}, FN:{}'.format(res_tp, res_fp, res_tn, res_fn))\n",
    "    print('#########################')\n",
    "#     i=+1\n",
    "\n",
    "    interp_tpr = np.interp(mean_fpr, fpr_res,tpr_res)\n",
    "    interp_tpr[0] = 0.0\n",
    "\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(auc_res)\n",
    "# print(XGB_result)\n",
    "print(performanceList)\n",
    "fig, ax = plt.subplots()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black',\n",
    "        label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr_xgb = np.mean(tprs, axis=0)\n",
    "mean_tpr_xgb[-1] = 1.0\n",
    "mean_auc_xgb = auc(mean_fpr, mean_tpr_xgb)\n",
    "std_auc_xgb = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr_xgb, color='maroon',\n",
    "        label=r'Mean ROC (AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc_xgb, std_auc_xgb),\n",
    "        lw=2, alpha=.8)\n",
    "ax.plot(mean_fpr, mean_tpr_xgb, color='maroon',\n",
    "        label=r'Mean ROC (AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc_xgb, std_auc_xgb),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "std_tpr_xgb = np.std(tprs, axis=0)\n",
    "tprs_upper_xgb = np.minimum(mean_tpr_xgb + std_tpr_xgb, 1)\n",
    "tprs_lower_xgb = np.maximum(mean_tpr_xgb - std_tpr_xgb, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower_xgb, tprs_upper_xgb, color='darkgray', alpha=.2,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Receiver operating characteristic\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "# fig.savefig('./result/0512/LR_embedded_cv5.jpg')\n",
    "# plt.figure(figsize=(20,20))\n",
    "plt.show()\n",
    "fig.savefig(savepath+'/result/basicCNN_cv5_first.jpg', dpi=300)\n",
    "\n",
    "np.save(savepath+'/result/mean_tpr_basicCNN_0512.npy', mean_tpr_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "check2 = np.load(savepath+'/npy/test_result_fold2.npy')\n",
    "checkimg = np.load(savepath+'/npy/test_x_fold2.npy')\n",
    "checklab = np.load(savepath+'/npy/test_y_fold2.npy')\n",
    "for ck in range(len(checkimg)):\n",
    "    io.imsave(savepath+'/check/{}_lab{}.jpg'.format(ck,checklab[ck]), checkimg[ck])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int or RandomState instance, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module keras.engine.training:\n",
      "\n",
      "fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, **kwargs) method of keras.engine.training.Model instance\n",
      "    Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      "    \n",
      "    # Arguments\n",
      "        x: Input data. It could be:\n",
      "            - A Numpy array (or array-like), or a list of arrays\n",
      "              (in case the model has multiple inputs).\n",
      "            - A dict mapping input names to the corresponding\n",
      "              array/tensors, if the model has named inputs.\n",
      "            - A generator or `keras.utils.Sequence` returning\n",
      "              `(inputs, targets)` or `(inputs, targets, sample weights)`.\n",
      "            - None (default) if feeding from framework-native\n",
      "              tensors (e.g. TensorFlow data tensors).\n",
      "        y: Target data. Like the input data `x`,\n",
      "            it could be either Numpy array(s), framework-native tensor(s),\n",
      "            list of Numpy arrays (if the model has multiple outputs) or\n",
      "            None (default) if feeding from framework-native tensors\n",
      "            (e.g. TensorFlow data tensors).\n",
      "            If output layers in the model are named, you can also pass a\n",
      "            dictionary mapping output names to Numpy arrays.\n",
      "            If `x` is a generator, or `keras.utils.Sequence` instance,\n",
      "            `y` should not be specified (since targets will be obtained\n",
      "            from `x`).\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per gradient update.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your data is in the\n",
      "            form of symbolic tensors, generators, or `Sequence` instances\n",
      "            (since they generate batches).\n",
      "        epochs: Integer. Number of epochs to train the model.\n",
      "            An epoch is an iteration over the entire `x` and `y`\n",
      "            data provided.\n",
      "            Note that in conjunction with `initial_epoch`,\n",
      "            `epochs` is to be understood as \"final epoch\".\n",
      "            The model is not trained for a number of iterations\n",
      "            given by `epochs`, but merely until the epoch\n",
      "            of index `epochs` is reached.\n",
      "        verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during training and validation\n",
      "            (if ).\n",
      "            See [callbacks](/callbacks).\n",
      "        validation_split: Float between 0 and 1.\n",
      "            Fraction of the training data to be used as validation data.\n",
      "            The model will set apart this fraction of the training data,\n",
      "            will not train on it, and will evaluate\n",
      "            the loss and any model metrics\n",
      "            on this data at the end of each epoch.\n",
      "            The validation data is selected from the last samples\n",
      "            in the `x` and `y` data provided, before shuffling.\n",
      "            This argument is not supported when `x` is a generator or\n",
      "            `Sequence` instance.\n",
      "        validation_data: Data on which to evaluate\n",
      "            the loss and any model metrics at the end of each epoch.\n",
      "            The model will not be trained on this data.\n",
      "            `validation_data` will override `validation_split`.\n",
      "            `validation_data` could be:\n",
      "                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      "                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      "                - dataset or a dataset iterator\n",
      "            For the first two cases, `batch_size` must be provided.\n",
      "            For the last case, `validation_steps` must be provided.\n",
      "        shuffle: Boolean (whether to shuffle the training data\n",
      "            before each epoch) or str (for 'batch').\n",
      "            'batch' is a special option for dealing with the\n",
      "            limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      "            Has no effect when `steps_per_epoch` is not `None`.\n",
      "        class_weight: Optional dictionary mapping class indices (integers)\n",
      "            to a weight (float) value, used for weighting the loss function\n",
      "            (during training only).\n",
      "            This can be useful to tell the model to\n",
      "            \"pay more attention\" to samples from\n",
      "            an under-represented class.\n",
      "        sample_weight: Optional Numpy array of weights for\n",
      "            the training samples, used for weighting the loss function\n",
      "            (during training only). You can either pass a flat (1D)\n",
      "            Numpy array with the same length as the input samples\n",
      "            (1:1 mapping between weights and samples),\n",
      "            or in the case of temporal data,\n",
      "            you can pass a 2D array with shape\n",
      "            `(samples, sequence_length)`,\n",
      "            to apply a different weight to every timestep of every sample.\n",
      "            In this case you should make sure to specify\n",
      "            `sample_weight_mode=\"temporal\"` in `compile()`. This argument\n",
      "            is not supported when `x` generator, or `Sequence` instance,\n",
      "            instead provide the sample_weights as the third element of `x`.\n",
      "        initial_epoch: Integer.\n",
      "            Epoch at which to start training\n",
      "            (useful for resuming a previous training run).\n",
      "        steps_per_epoch: Integer or `None`.\n",
      "            Total number of steps (batches of samples)\n",
      "            before declaring one epoch finished and starting the\n",
      "            next epoch. When training with input tensors such as\n",
      "            TensorFlow data tensors, the default `None` is equal to\n",
      "            the number of samples in your dataset divided by\n",
      "            the batch size, or 1 if that cannot be determined.\n",
      "        validation_steps: Only relevant if `steps_per_epoch`\n",
      "            is specified. Total number of steps (batches of samples)\n",
      "            to validate before stopping.\n",
      "        validation_steps: Only relevant if `validation_data` is provided\n",
      "            and is a generator. Total number of steps (batches of samples)\n",
      "            to draw before stopping when performing validation at the end\n",
      "            of every epoch.\n",
      "        validation_freq: Only relevant if validation data is provided. Integer\n",
      "            or list/tuple/set. If an integer, specifies how many training\n",
      "            epochs to run before a new validation run is performed, e.g.\n",
      "            `validation_freq=2` runs validation every 2 epochs. If a list,\n",
      "            tuple, or set, specifies the epochs on which to run validation,\n",
      "            e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n",
      "            of the 1st, 2nd, and 10th epochs.\n",
      "        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "            input only. Maximum size for the generator queue.\n",
      "            If unspecified, `max_queue_size` will default to 10.\n",
      "        workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "            only. Maximum number of processes to spin up\n",
      "            when using process-based threading. If unspecified, `workers`\n",
      "            will default to 1. If 0, will execute the generator on the main\n",
      "            thread.\n",
      "        use_multiprocessing: Boolean. Used for generator or\n",
      "            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "            threading. If unspecified, `use_multiprocessing` will default to\n",
      "            `False`. Note that because this implementation relies on\n",
      "            multiprocessing, you should not pass non-picklable arguments to\n",
      "            the generator as they can't be passed easily to children processes.\n",
      "        **kwargs: Used for backwards compatibility.\n",
      "    \n",
      "    # Returns\n",
      "        A `History` object. Its `History.history` attribute is\n",
      "        a record of training loss values and metrics values\n",
      "        at successive epochs, as well as validation loss values\n",
      "        and validation metrics values (if applicable).\n",
      "    \n",
      "    # Raises\n",
      "        RuntimeError: If the model was never compiled.\n",
      "        ValueError: In case of mismatch between the provided input data\n",
      "            and what the model expects.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(?, 15, 15, 4)\n",
      "1\n",
      "(?, 15, 15, 4) 2 1 4\n",
      "input\n",
      "shortcut: (?, 15, 15, 4)\n",
      "x: (?, 15, 15, 4)\n",
      "before add\n",
      "shortcut: (?, 15, 15, 8)\n",
      "x: (?, 15, 15, 8)\n",
      "(?, 15, 15, 8)\n",
      "8\n",
      "(?, 7, 7, 8)\n",
      "8\n",
      "4\n",
      "4\n",
      "2\n",
      "Train on 1040 samples, validate on 259 samples\n",
      "Epoch 1/500\n",
      "1040/1040 [==============================] - 4s 4ms/step - loss: 0.7393 - accuracy: 0.4808 - val_loss: 17.5577 - val_accuracy: 0.4981\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 17.55765, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 2/500\n",
      "1040/1040 [==============================] - 0s 221us/step - loss: 0.6434 - accuracy: 0.6798 - val_loss: 3.2610 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00002: val_loss improved from 17.55765 to 3.26097, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 3/500\n",
      "1040/1040 [==============================] - 0s 186us/step - loss: 0.5888 - accuracy: 0.7692 - val_loss: 0.7991 - val_accuracy: 0.5251\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.26097 to 0.79906, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 4/500\n",
      "1040/1040 [==============================] - 0s 250us/step - loss: 0.5308 - accuracy: 0.8135 - val_loss: 0.5961 - val_accuracy: 0.6873\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.79906 to 0.59615, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 5/500\n",
      "1040/1040 [==============================] - 0s 195us/step - loss: 0.4543 - accuracy: 0.8519 - val_loss: 0.6644 - val_accuracy: 0.5483\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.59615\n",
      "Epoch 6/500\n",
      "1040/1040 [==============================] - 0s 210us/step - loss: 0.3672 - accuracy: 0.8904 - val_loss: 0.6962 - val_accuracy: 0.5251\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.59615\n",
      "Epoch 7/500\n",
      "1040/1040 [==============================] - 0s 258us/step - loss: 0.2993 - accuracy: 0.9115 - val_loss: 0.7012 - val_accuracy: 0.5135\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.59615\n",
      "Epoch 8/500\n",
      "1040/1040 [==============================] - 0s 280us/step - loss: 0.2472 - accuracy: 0.9298 - val_loss: 0.7052 - val_accuracy: 0.5290\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.59615\n",
      "Epoch 9/500\n",
      "1040/1040 [==============================] - 0s 244us/step - loss: 0.2098 - accuracy: 0.9413 - val_loss: 0.7192 - val_accuracy: 0.5328\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.59615\n",
      "Epoch 10/500\n",
      "1040/1040 [==============================] - 0s 245us/step - loss: 0.1828 - accuracy: 0.9510 - val_loss: 0.7389 - val_accuracy: 0.5405\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.59615\n",
      "Epoch 11/500\n",
      "1040/1040 [==============================] - 0s 165us/step - loss: 0.1629 - accuracy: 0.9519 - val_loss: 0.7551 - val_accuracy: 0.5483\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.59615\n",
      "Epoch 12/500\n",
      "1040/1040 [==============================] - 0s 212us/step - loss: 0.1477 - accuracy: 0.9548 - val_loss: 0.7643 - val_accuracy: 0.5637\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.59615\n",
      "Epoch 13/500\n",
      "1040/1040 [==============================] - 0s 209us/step - loss: 0.1360 - accuracy: 0.9558 - val_loss: 0.7658 - val_accuracy: 0.5676\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.59615\n",
      "Epoch 14/500\n",
      "1040/1040 [==============================] - 0s 317us/step - loss: 0.1265 - accuracy: 0.9567 - val_loss: 0.7524 - val_accuracy: 0.6062\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.59615\n",
      "Epoch 15/500\n",
      "1040/1040 [==============================] - 0s 235us/step - loss: 0.1207 - accuracy: 0.9577 - val_loss: 0.7103 - val_accuracy: 0.6255\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.59615\n",
      "Epoch 16/500\n",
      "1040/1040 [==============================] - 0s 264us/step - loss: 0.1200 - accuracy: 0.9587 - val_loss: 0.6507 - val_accuracy: 0.6486\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.59615\n",
      "Epoch 17/500\n",
      "1040/1040 [==============================] - 0s 142us/step - loss: 0.1192 - accuracy: 0.9587 - val_loss: 0.5803 - val_accuracy: 0.6988\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.59615 to 0.58034, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 18/500\n",
      "1040/1040 [==============================] - 0s 196us/step - loss: 0.1185 - accuracy: 0.9587 - val_loss: 0.5111 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.58034 to 0.51105, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 19/500\n",
      "1040/1040 [==============================] - 0s 213us/step - loss: 0.1178 - accuracy: 0.9587 - val_loss: 0.4469 - val_accuracy: 0.7722\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.51105 to 0.44688, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 20/500\n",
      "1040/1040 [==============================] - 0s 253us/step - loss: 0.1170 - accuracy: 0.9587 - val_loss: 0.3918 - val_accuracy: 0.7992\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.44688 to 0.39180, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 21/500\n",
      "1040/1040 [==============================] - 0s 219us/step - loss: 0.1163 - accuracy: 0.9587 - val_loss: 0.3489 - val_accuracy: 0.8456\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.39180 to 0.34885, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 22/500\n",
      "1040/1040 [==============================] - 0s 201us/step - loss: 0.1155 - accuracy: 0.9587 - val_loss: 0.3155 - val_accuracy: 0.8726\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.34885 to 0.31550, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 23/500\n",
      "1040/1040 [==============================] - 0s 200us/step - loss: 0.1147 - accuracy: 0.9587 - val_loss: 0.2893 - val_accuracy: 0.8803\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.31550 to 0.28927, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 24/500\n",
      "1040/1040 [==============================] - 0s 264us/step - loss: 0.1140 - accuracy: 0.9606 - val_loss: 0.2677 - val_accuracy: 0.8958\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.28927 to 0.26774, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 25/500\n",
      "1040/1040 [==============================] - 0s 284us/step - loss: 0.1132 - accuracy: 0.9606 - val_loss: 0.2502 - val_accuracy: 0.9035\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.26774 to 0.25018, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 26/500\n",
      "1040/1040 [==============================] - 0s 245us/step - loss: 0.1125 - accuracy: 0.9606 - val_loss: 0.2353 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.25018 to 0.23535, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 27/500\n",
      "1040/1040 [==============================] - 0s 257us/step - loss: 0.1117 - accuracy: 0.9606 - val_loss: 0.2224 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.23535 to 0.22239, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 28/500\n",
      "1040/1040 [==============================] - 0s 239us/step - loss: 0.1110 - accuracy: 0.9606 - val_loss: 0.2106 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.22239 to 0.21064, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 29/500\n",
      "1040/1040 [==============================] - 0s 273us/step - loss: 0.1102 - accuracy: 0.9615 - val_loss: 0.2001 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.21064 to 0.20011, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 30/500\n",
      "1040/1040 [==============================] - 0s 217us/step - loss: 0.1095 - accuracy: 0.9615 - val_loss: 0.1911 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20011 to 0.19106, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 31/500\n",
      "1040/1040 [==============================] - 0s 224us/step - loss: 0.1088 - accuracy: 0.9615 - val_loss: 0.1835 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19106 to 0.18348, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 32/500\n",
      "1040/1040 [==============================] - 0s 226us/step - loss: 0.1081 - accuracy: 0.9615 - val_loss: 0.1772 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.18348 to 0.17724, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 33/500\n",
      "1040/1040 [==============================] - 0s 226us/step - loss: 0.1074 - accuracy: 0.9615 - val_loss: 0.1714 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.17724 to 0.17140, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 34/500\n",
      "1040/1040 [==============================] - 0s 241us/step - loss: 0.1067 - accuracy: 0.9615 - val_loss: 0.1665 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.17140 to 0.16646, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 35/500\n",
      "1040/1040 [==============================] - 0s 226us/step - loss: 0.1060 - accuracy: 0.9615 - val_loss: 0.1623 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.16646 to 0.16231, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 36/500\n",
      "1040/1040 [==============================] - 0s 281us/step - loss: 0.1053 - accuracy: 0.9615 - val_loss: 0.1587 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.16231 to 0.15875, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 37/500\n",
      "1040/1040 [==============================] - 0s 215us/step - loss: 0.1046 - accuracy: 0.9615 - val_loss: 0.1554 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.15875 to 0.15542, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 38/500\n",
      "1040/1040 [==============================] - 0s 227us/step - loss: 0.1039 - accuracy: 0.9625 - val_loss: 0.1524 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.15542 to 0.15241, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 39/500\n",
      "1040/1040 [==============================] - 0s 349us/step - loss: 0.1032 - accuracy: 0.9625 - val_loss: 0.1496 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.15241 to 0.14956, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 40/500\n",
      "1040/1040 [==============================] - 0s 227us/step - loss: 0.1025 - accuracy: 0.9635 - val_loss: 0.1469 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.14956 to 0.14694, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 41/500\n",
      "1040/1040 [==============================] - 0s 190us/step - loss: 0.1019 - accuracy: 0.9635 - val_loss: 0.1447 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.14694 to 0.14473, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 42/500\n",
      "1040/1040 [==============================] - 0s 264us/step - loss: 0.1012 - accuracy: 0.9644 - val_loss: 0.1428 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.14473 to 0.14277, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 43/500\n",
      "1040/1040 [==============================] - 0s 219us/step - loss: 0.1005 - accuracy: 0.9654 - val_loss: 0.1409 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.14277 to 0.14092, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 44/500\n",
      "1040/1040 [==============================] - 0s 278us/step - loss: 0.0999 - accuracy: 0.9654 - val_loss: 0.1392 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.14092 to 0.13923, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 45/500\n",
      "1040/1040 [==============================] - 0s 197us/step - loss: 0.0992 - accuracy: 0.9654 - val_loss: 0.1377 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.13923 to 0.13770, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 46/500\n",
      "1040/1040 [==============================] - 0s 298us/step - loss: 0.0986 - accuracy: 0.9654 - val_loss: 0.1363 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.13770 to 0.13630, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 47/500\n",
      "1040/1040 [==============================] - 0s 231us/step - loss: 0.0980 - accuracy: 0.9663 - val_loss: 0.1350 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.13630 to 0.13495, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 48/500\n",
      "1040/1040 [==============================] - 0s 215us/step - loss: 0.0973 - accuracy: 0.9663 - val_loss: 0.1337 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.13495 to 0.13370, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 49/500\n",
      "1040/1040 [==============================] - 0s 305us/step - loss: 0.0967 - accuracy: 0.9663 - val_loss: 0.1325 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.13370 to 0.13253, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 50/500\n",
      "1040/1040 [==============================] - 0s 213us/step - loss: 0.0961 - accuracy: 0.9663 - val_loss: 0.1315 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.13253 to 0.13151, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 51/500\n",
      "1040/1040 [==============================] - 0s 257us/step - loss: 0.0955 - accuracy: 0.9663 - val_loss: 0.1305 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.13151 to 0.13054, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 52/500\n",
      "1040/1040 [==============================] - 0s 262us/step - loss: 0.0949 - accuracy: 0.9663 - val_loss: 0.1296 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.13054 to 0.12960, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 53/500\n",
      "1040/1040 [==============================] - 0s 196us/step - loss: 0.0943 - accuracy: 0.9663 - val_loss: 0.1287 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.12960 to 0.12871, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 54/500\n",
      "1040/1040 [==============================] - 0s 310us/step - loss: 0.0937 - accuracy: 0.9663 - val_loss: 0.1278 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.12871 to 0.12780, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 55/500\n",
      "1040/1040 [==============================] - 0s 186us/step - loss: 0.0931 - accuracy: 0.9663 - val_loss: 0.1269 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.12780 to 0.12693, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 56/500\n",
      "1040/1040 [==============================] - 0s 281us/step - loss: 0.0925 - accuracy: 0.9663 - val_loss: 0.1261 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12693 to 0.12609, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 57/500\n",
      "1040/1040 [==============================] - 0s 260us/step - loss: 0.0919 - accuracy: 0.9663 - val_loss: 0.1253 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12609 to 0.12527, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 58/500\n",
      "1040/1040 [==============================] - 0s 230us/step - loss: 0.0914 - accuracy: 0.9663 - val_loss: 0.1245 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12527 to 0.12451, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 59/500\n",
      "1040/1040 [==============================] - 0s 255us/step - loss: 0.0908 - accuracy: 0.9663 - val_loss: 0.1238 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.12451 to 0.12378, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 60/500\n",
      "1040/1040 [==============================] - 0s 309us/step - loss: 0.0902 - accuracy: 0.9663 - val_loss: 0.1231 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.12378 to 0.12307, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 61/500\n",
      "1040/1040 [==============================] - 0s 216us/step - loss: 0.0897 - accuracy: 0.9663 - val_loss: 0.1224 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.12307 to 0.12237, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 62/500\n",
      "1040/1040 [==============================] - 0s 127us/step - loss: 0.0891 - accuracy: 0.9663 - val_loss: 0.1217 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.12237 to 0.12167, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 63/500\n",
      "1040/1040 [==============================] - 0s 221us/step - loss: 0.0886 - accuracy: 0.9663 - val_loss: 0.1210 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.12167 to 0.12098, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 64/500\n",
      "1040/1040 [==============================] - 0s 243us/step - loss: 0.0880 - accuracy: 0.9663 - val_loss: 0.1203 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.12098 to 0.12029, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 65/500\n",
      "1040/1040 [==============================] - 0s 252us/step - loss: 0.0875 - accuracy: 0.9663 - val_loss: 0.1197 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.12029 to 0.11968, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 66/500\n",
      "1040/1040 [==============================] - 0s 332us/step - loss: 0.0870 - accuracy: 0.9663 - val_loss: 0.1191 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.11968 to 0.11910, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 67/500\n",
      "1040/1040 [==============================] - 0s 218us/step - loss: 0.0864 - accuracy: 0.9663 - val_loss: 0.1185 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.11910 to 0.11852, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 68/500\n",
      "1040/1040 [==============================] - 0s 237us/step - loss: 0.0859 - accuracy: 0.9663 - val_loss: 0.1180 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.11852 to 0.11799, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 69/500\n",
      "1040/1040 [==============================] - 0s 279us/step - loss: 0.0854 - accuracy: 0.9663 - val_loss: 0.1175 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.11799 to 0.11751, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 70/500\n",
      "1040/1040 [==============================] - 0s 234us/step - loss: 0.0849 - accuracy: 0.9663 - val_loss: 0.1170 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.11751 to 0.11701, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 71/500\n",
      "1040/1040 [==============================] - 0s 241us/step - loss: 0.0844 - accuracy: 0.9663 - val_loss: 0.1165 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.11701 to 0.11652, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 72/500\n",
      "1040/1040 [==============================] - 0s 235us/step - loss: 0.0839 - accuracy: 0.9663 - val_loss: 0.1160 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.11652 to 0.11601, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 73/500\n",
      "1040/1040 [==============================] - 0s 258us/step - loss: 0.0834 - accuracy: 0.9663 - val_loss: 0.1155 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.11601 to 0.11549, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 74/500\n",
      "1040/1040 [==============================] - 0s 271us/step - loss: 0.0829 - accuracy: 0.9663 - val_loss: 0.1150 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.11549 to 0.11498, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 75/500\n",
      "1040/1040 [==============================] - 0s 250us/step - loss: 0.0824 - accuracy: 0.9663 - val_loss: 0.1145 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.11498 to 0.11450, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 76/500\n",
      "1040/1040 [==============================] - 0s 231us/step - loss: 0.0819 - accuracy: 0.9663 - val_loss: 0.1140 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.11450 to 0.11401, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 77/500\n",
      "1040/1040 [==============================] - 0s 302us/step - loss: 0.0814 - accuracy: 0.9663 - val_loss: 0.1135 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.11401 to 0.11352, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 78/500\n",
      "1040/1040 [==============================] - 0s 219us/step - loss: 0.0809 - accuracy: 0.9663 - val_loss: 0.1131 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.11352 to 0.11305, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 79/500\n",
      "1040/1040 [==============================] - 0s 242us/step - loss: 0.0805 - accuracy: 0.9663 - val_loss: 0.1126 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.11305 to 0.11262, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 80/500\n",
      "1040/1040 [==============================] - 0s 284us/step - loss: 0.0800 - accuracy: 0.9673 - val_loss: 0.1121 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.11262 to 0.11213, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 81/500\n",
      "1040/1040 [==============================] - 0s 230us/step - loss: 0.0796 - accuracy: 0.9673 - val_loss: 0.1117 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.11213 to 0.11166, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 82/500\n",
      "1040/1040 [==============================] - 0s 221us/step - loss: 0.0791 - accuracy: 0.9673 - val_loss: 0.1112 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.11166 to 0.11123, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 83/500\n",
      "1040/1040 [==============================] - 0s 215us/step - loss: 0.0786 - accuracy: 0.9673 - val_loss: 0.1108 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.11123 to 0.11075, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 84/500\n",
      "1040/1040 [==============================] - 0s 223us/step - loss: 0.0782 - accuracy: 0.9673 - val_loss: 0.1102 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.11075 to 0.11024, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 85/500\n",
      "1040/1040 [==============================] - 0s 251us/step - loss: 0.0777 - accuracy: 0.9673 - val_loss: 0.1097 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.11024 to 0.10974, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 86/500\n",
      "1040/1040 [==============================] - 0s 343us/step - loss: 0.0772 - accuracy: 0.9673 - val_loss: 0.1093 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.10974 to 0.10927, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 87/500\n",
      "1040/1040 [==============================] - 0s 220us/step - loss: 0.0768 - accuracy: 0.9673 - val_loss: 0.1088 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.10927 to 0.10882, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 88/500\n",
      "1040/1040 [==============================] - 0s 224us/step - loss: 0.0763 - accuracy: 0.9673 - val_loss: 0.1084 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.10882 to 0.10835, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 89/500\n",
      "1040/1040 [==============================] - 0s 326us/step - loss: 0.0758 - accuracy: 0.9683 - val_loss: 0.1079 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.10835 to 0.10788, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 90/500\n",
      "1040/1040 [==============================] - 0s 224us/step - loss: 0.0754 - accuracy: 0.9683 - val_loss: 0.1074 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.10788 to 0.10741, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 91/500\n",
      "1040/1040 [==============================] - 0s 234us/step - loss: 0.0749 - accuracy: 0.9683 - val_loss: 0.1070 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.10741 to 0.10695, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 92/500\n",
      "1040/1040 [==============================] - 0s 241us/step - loss: 0.0745 - accuracy: 0.9683 - val_loss: 0.1065 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.10695 to 0.10651, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 93/500\n",
      "1040/1040 [==============================] - 0s 242us/step - loss: 0.0741 - accuracy: 0.9683 - val_loss: 0.1061 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.10651 to 0.10612, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 94/500\n",
      "1040/1040 [==============================] - 0s 285us/step - loss: 0.0736 - accuracy: 0.9683 - val_loss: 0.1057 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.10612 to 0.10574, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 95/500\n",
      "1040/1040 [==============================] - 0s 251us/step - loss: 0.0732 - accuracy: 0.9692 - val_loss: 0.1054 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.10574 to 0.10535, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 96/500\n",
      "1040/1040 [==============================] - 0s 228us/step - loss: 0.0728 - accuracy: 0.9692 - val_loss: 0.1050 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.10535 to 0.10497, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 97/500\n",
      "1040/1040 [==============================] - 0s 276us/step - loss: 0.0723 - accuracy: 0.9692 - val_loss: 0.1046 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.10497 to 0.10461, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 98/500\n",
      "1040/1040 [==============================] - 0s 212us/step - loss: 0.0719 - accuracy: 0.9692 - val_loss: 0.1042 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.10461 to 0.10425, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 99/500\n",
      "1040/1040 [==============================] - 0s 219us/step - loss: 0.0715 - accuracy: 0.9692 - val_loss: 0.1039 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.10425 to 0.10390, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 100/500\n",
      "1040/1040 [==============================] - 0s 247us/step - loss: 0.0711 - accuracy: 0.9702 - val_loss: 0.1036 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.10390 to 0.10356, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 101/500\n",
      "1040/1040 [==============================] - 0s 241us/step - loss: 0.0706 - accuracy: 0.9702 - val_loss: 0.1032 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.10356 to 0.10323, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 102/500\n",
      "1040/1040 [==============================] - 0s 298us/step - loss: 0.0702 - accuracy: 0.9702 - val_loss: 0.1029 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.10323 to 0.10290, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 103/500\n",
      "1040/1040 [==============================] - 0s 230us/step - loss: 0.0698 - accuracy: 0.9712 - val_loss: 0.1026 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.10290 to 0.10256, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 104/500\n",
      "1040/1040 [==============================] - 0s 190us/step - loss: 0.0694 - accuracy: 0.9721 - val_loss: 0.1022 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.10256 to 0.10221, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 105/500\n",
      "1040/1040 [==============================] - 0s 291us/step - loss: 0.0690 - accuracy: 0.9721 - val_loss: 0.1019 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.10221 to 0.10185, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 106/500\n",
      "1040/1040 [==============================] - 0s 225us/step - loss: 0.0686 - accuracy: 0.9721 - val_loss: 0.1015 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.10185 to 0.10151, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 107/500\n",
      "1040/1040 [==============================] - 0s 200us/step - loss: 0.0682 - accuracy: 0.9721 - val_loss: 0.1012 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.10151 to 0.10120, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 108/500\n",
      "1040/1040 [==============================] - 0s 252us/step - loss: 0.0678 - accuracy: 0.9731 - val_loss: 0.1009 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.10120 to 0.10091, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 109/500\n",
      "1040/1040 [==============================] - 0s 223us/step - loss: 0.0674 - accuracy: 0.9740 - val_loss: 0.1006 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.10091 to 0.10059, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 110/500\n",
      "1040/1040 [==============================] - 0s 222us/step - loss: 0.0670 - accuracy: 0.9740 - val_loss: 0.1003 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.10059 to 0.10027, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 111/500\n",
      "1040/1040 [==============================] - 0s 274us/step - loss: 0.0666 - accuracy: 0.9740 - val_loss: 0.0999 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.10027 to 0.09995, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 112/500\n",
      "1040/1040 [==============================] - 0s 236us/step - loss: 0.0662 - accuracy: 0.9740 - val_loss: 0.0996 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.09995 to 0.09964, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 113/500\n",
      "1040/1040 [==============================] - 0s 153us/step - loss: 0.0658 - accuracy: 0.9740 - val_loss: 0.0993 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.09964 to 0.09932, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 114/500\n",
      "1040/1040 [==============================] - 0s 262us/step - loss: 0.0654 - accuracy: 0.9740 - val_loss: 0.0990 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.09932 to 0.09902, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 115/500\n",
      "1040/1040 [==============================] - 0s 197us/step - loss: 0.0650 - accuracy: 0.9740 - val_loss: 0.0987 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.09902 to 0.09870, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 116/500\n",
      "1040/1040 [==============================] - 0s 215us/step - loss: 0.0646 - accuracy: 0.9750 - val_loss: 0.0984 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.09870 to 0.09838, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 117/500\n",
      "1040/1040 [==============================] - 0s 224us/step - loss: 0.0642 - accuracy: 0.9760 - val_loss: 0.0981 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.09838 to 0.09810, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 118/500\n",
      "1040/1040 [==============================] - 0s 211us/step - loss: 0.0638 - accuracy: 0.9760 - val_loss: 0.0978 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.09810 to 0.09777, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 119/500\n",
      "1040/1040 [==============================] - 0s 217us/step - loss: 0.0634 - accuracy: 0.9769 - val_loss: 0.0975 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.09777 to 0.09748, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 120/500\n",
      "1040/1040 [==============================] - 0s 228us/step - loss: 0.0631 - accuracy: 0.9779 - val_loss: 0.0972 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.09748 to 0.09719, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 121/500\n",
      "1040/1040 [==============================] - 0s 224us/step - loss: 0.0627 - accuracy: 0.9779 - val_loss: 0.0969 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.09719 to 0.09692, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 122/500\n",
      "1040/1040 [==============================] - 0s 216us/step - loss: 0.0623 - accuracy: 0.9779 - val_loss: 0.0967 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.09692 to 0.09668, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 123/500\n",
      "1040/1040 [==============================] - 0s 193us/step - loss: 0.0619 - accuracy: 0.9779 - val_loss: 0.0964 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.09668 to 0.09643, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 124/500\n",
      "1040/1040 [==============================] - 0s 242us/step - loss: 0.0615 - accuracy: 0.9779 - val_loss: 0.0962 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.09643 to 0.09617, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 125/500\n",
      "1040/1040 [==============================] - 0s 187us/step - loss: 0.0612 - accuracy: 0.9779 - val_loss: 0.0959 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.09617 to 0.09589, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 126/500\n",
      "1040/1040 [==============================] - 0s 241us/step - loss: 0.0608 - accuracy: 0.9788 - val_loss: 0.0956 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.09589 to 0.09562, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 127/500\n",
      "1040/1040 [==============================] - 0s 187us/step - loss: 0.0604 - accuracy: 0.9798 - val_loss: 0.0953 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.09562 to 0.09534, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 128/500\n",
      "1040/1040 [==============================] - 0s 297us/step - loss: 0.0600 - accuracy: 0.9808 - val_loss: 0.0950 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.09534 to 0.09505, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 129/500\n",
      "1040/1040 [==============================] - 0s 225us/step - loss: 0.0596 - accuracy: 0.9808 - val_loss: 0.0947 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.09505 to 0.09472, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 130/500\n",
      "1040/1040 [==============================] - 0s 211us/step - loss: 0.0593 - accuracy: 0.9808 - val_loss: 0.0944 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.09472 to 0.09440, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 131/500\n",
      "1040/1040 [==============================] - 0s 210us/step - loss: 0.0589 - accuracy: 0.9808 - val_loss: 0.0941 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.09440 to 0.09412, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 132/500\n",
      "1040/1040 [==============================] - 0s 178us/step - loss: 0.0585 - accuracy: 0.9808 - val_loss: 0.0938 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.09412 to 0.09383, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 133/500\n",
      "1040/1040 [==============================] - 0s 302us/step - loss: 0.0581 - accuracy: 0.9808 - val_loss: 0.0936 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.09383 to 0.09356, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 134/500\n",
      "1040/1040 [==============================] - 0s 210us/step - loss: 0.0577 - accuracy: 0.9808 - val_loss: 0.0932 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.09356 to 0.09321, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 135/500\n",
      "1040/1040 [==============================] - 0s 223us/step - loss: 0.0573 - accuracy: 0.9808 - val_loss: 0.0929 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.09321 to 0.09289, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 136/500\n",
      "1040/1040 [==============================] - 0s 242us/step - loss: 0.0570 - accuracy: 0.9808 - val_loss: 0.0926 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.09289 to 0.09260, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 137/500\n",
      "1040/1040 [==============================] - 0s 181us/step - loss: 0.0566 - accuracy: 0.9808 - val_loss: 0.0924 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.09260 to 0.09235, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 138/500\n",
      "1040/1040 [==============================] - 0s 269us/step - loss: 0.0562 - accuracy: 0.9817 - val_loss: 0.0921 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.09235 to 0.09207, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 139/500\n",
      "1040/1040 [==============================] - 0s 239us/step - loss: 0.0558 - accuracy: 0.9817 - val_loss: 0.0917 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.09207 to 0.09175, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 140/500\n",
      "1040/1040 [==============================] - 0s 200us/step - loss: 0.0554 - accuracy: 0.9827 - val_loss: 0.0915 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.09175 to 0.09148, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 141/500\n",
      "1040/1040 [==============================] - 0s 222us/step - loss: 0.0551 - accuracy: 0.9827 - val_loss: 0.0912 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.09148 to 0.09124, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 142/500\n",
      "1040/1040 [==============================] - 0s 226us/step - loss: 0.0547 - accuracy: 0.9827 - val_loss: 0.0910 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.09124 to 0.09100, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 143/500\n",
      "1040/1040 [==============================] - 0s 282us/step - loss: 0.0543 - accuracy: 0.9837 - val_loss: 0.0907 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.09100 to 0.09073, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 144/500\n",
      "1040/1040 [==============================] - 0s 220us/step - loss: 0.0540 - accuracy: 0.9837 - val_loss: 0.0905 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.09073 to 0.09048, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 145/500\n",
      "1040/1040 [==============================] - 0s 214us/step - loss: 0.0536 - accuracy: 0.9837 - val_loss: 0.0902 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.09048 to 0.09024, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 146/500\n",
      "1040/1040 [==============================] - 0s 378us/step - loss: 0.0533 - accuracy: 0.9846 - val_loss: 0.0900 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.09024 to 0.08999, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 147/500\n",
      "1040/1040 [==============================] - 0s 225us/step - loss: 0.0530 - accuracy: 0.9856 - val_loss: 0.0897 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.08999 to 0.08970, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 148/500\n",
      "1040/1040 [==============================] - 0s 239us/step - loss: 0.0526 - accuracy: 0.9865 - val_loss: 0.0894 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.08970 to 0.08942, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 149/500\n",
      "1040/1040 [==============================] - 0s 259us/step - loss: 0.0523 - accuracy: 0.9865 - val_loss: 0.0891 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.08942 to 0.08912, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 150/500\n",
      "1040/1040 [==============================] - 0s 192us/step - loss: 0.0520 - accuracy: 0.9865 - val_loss: 0.0889 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.08912 to 0.08887, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 151/500\n",
      "1040/1040 [==============================] - 0s 243us/step - loss: 0.0516 - accuracy: 0.9865 - val_loss: 0.0886 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.08887 to 0.08862, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 152/500\n",
      "1040/1040 [==============================] - 0s 268us/step - loss: 0.0513 - accuracy: 0.9865 - val_loss: 0.0884 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.08862 to 0.08836, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 153/500\n",
      "1040/1040 [==============================] - 0s 252us/step - loss: 0.0509 - accuracy: 0.9865 - val_loss: 0.0881 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.08836 to 0.08811, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 154/500\n",
      "1040/1040 [==============================] - 0s 221us/step - loss: 0.0506 - accuracy: 0.9865 - val_loss: 0.0878 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.08811 to 0.08784, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 155/500\n",
      "1040/1040 [==============================] - 0s 209us/step - loss: 0.0503 - accuracy: 0.9865 - val_loss: 0.0876 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.08784 to 0.08759, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 156/500\n",
      "1040/1040 [==============================] - 0s 252us/step - loss: 0.0500 - accuracy: 0.9865 - val_loss: 0.0874 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.08759 to 0.08739, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 157/500\n",
      "1040/1040 [==============================] - 0s 209us/step - loss: 0.0496 - accuracy: 0.9865 - val_loss: 0.0872 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.08739 to 0.08716, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 158/500\n",
      "1040/1040 [==============================] - 0s 259us/step - loss: 0.0493 - accuracy: 0.9865 - val_loss: 0.0869 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.08716 to 0.08694, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 159/500\n",
      "1040/1040 [==============================] - 0s 231us/step - loss: 0.0490 - accuracy: 0.9865 - val_loss: 0.0867 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.08694 to 0.08670, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 160/500\n",
      "1040/1040 [==============================] - 0s 176us/step - loss: 0.0487 - accuracy: 0.9865 - val_loss: 0.0865 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.08670 to 0.08652, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 161/500\n",
      "1040/1040 [==============================] - 0s 284us/step - loss: 0.0483 - accuracy: 0.9865 - val_loss: 0.0863 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.08652 to 0.08633, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 162/500\n",
      "1040/1040 [==============================] - 0s 219us/step - loss: 0.0480 - accuracy: 0.9865 - val_loss: 0.0861 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.08633 to 0.08614, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 163/500\n",
      "1040/1040 [==============================] - 0s 274us/step - loss: 0.0477 - accuracy: 0.9865 - val_loss: 0.0859 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.08614 to 0.08595, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 164/500\n",
      "1040/1040 [==============================] - 0s 219us/step - loss: 0.0474 - accuracy: 0.9865 - val_loss: 0.0858 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.08595 to 0.08577, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 165/500\n",
      "1040/1040 [==============================] - 0s 211us/step - loss: 0.0471 - accuracy: 0.9865 - val_loss: 0.0856 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.08577 to 0.08558, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 166/500\n",
      "1040/1040 [==============================] - 0s 216us/step - loss: 0.0468 - accuracy: 0.9865 - val_loss: 0.0854 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.08558 to 0.08543, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 167/500\n",
      "1040/1040 [==============================] - 0s 218us/step - loss: 0.0465 - accuracy: 0.9865 - val_loss: 0.0852 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.08543 to 0.08522, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 168/500\n",
      "1040/1040 [==============================] - 0s 255us/step - loss: 0.0462 - accuracy: 0.9865 - val_loss: 0.0850 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.08522 to 0.08500, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 169/500\n",
      "1040/1040 [==============================] - 0s 246us/step - loss: 0.0459 - accuracy: 0.9865 - val_loss: 0.0848 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.08500 to 0.08479, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 170/500\n",
      "1040/1040 [==============================] - 0s 187us/step - loss: 0.0456 - accuracy: 0.9875 - val_loss: 0.0846 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.08479 to 0.08464, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 171/500\n",
      "1040/1040 [==============================] - 0s 270us/step - loss: 0.0453 - accuracy: 0.9875 - val_loss: 0.0845 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.08464 to 0.08449, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 172/500\n",
      "1040/1040 [==============================] - 0s 224us/step - loss: 0.0450 - accuracy: 0.9875 - val_loss: 0.0843 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.08449 to 0.08434, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 173/500\n",
      "1040/1040 [==============================] - 0s 228us/step - loss: 0.0447 - accuracy: 0.9875 - val_loss: 0.0842 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.08434 to 0.08420, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 174/500\n",
      "1040/1040 [==============================] - 0s 249us/step - loss: 0.0444 - accuracy: 0.9875 - val_loss: 0.0841 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.08420 to 0.08407, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 175/500\n",
      "1040/1040 [==============================] - 0s 184us/step - loss: 0.0441 - accuracy: 0.9875 - val_loss: 0.0839 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.08407 to 0.08391, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 176/500\n",
      "1040/1040 [==============================] - 0s 246us/step - loss: 0.0439 - accuracy: 0.9875 - val_loss: 0.0838 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.08391 to 0.08377, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 177/500\n",
      "1040/1040 [==============================] - 0s 235us/step - loss: 0.0436 - accuracy: 0.9885 - val_loss: 0.0836 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.08377 to 0.08361, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 178/500\n",
      "1040/1040 [==============================] - 0s 201us/step - loss: 0.0433 - accuracy: 0.9885 - val_loss: 0.0835 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.08361 to 0.08346, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 179/500\n",
      "1040/1040 [==============================] - 0s 251us/step - loss: 0.0430 - accuracy: 0.9885 - val_loss: 0.0834 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.08346 to 0.08336, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 180/500\n",
      "1040/1040 [==============================] - 0s 259us/step - loss: 0.0427 - accuracy: 0.9885 - val_loss: 0.0832 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.08336 to 0.08319, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 181/500\n",
      "1040/1040 [==============================] - 0s 210us/step - loss: 0.0425 - accuracy: 0.9885 - val_loss: 0.0830 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.08319 to 0.08303, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 182/500\n",
      "1040/1040 [==============================] - 0s 244us/step - loss: 0.0422 - accuracy: 0.9885 - val_loss: 0.0829 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.08303 to 0.08293, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 183/500\n",
      "1040/1040 [==============================] - 0s 224us/step - loss: 0.0419 - accuracy: 0.9885 - val_loss: 0.0828 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.08293 to 0.08281, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 184/500\n",
      "1040/1040 [==============================] - 0s 254us/step - loss: 0.0417 - accuracy: 0.9885 - val_loss: 0.0827 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.08281 to 0.08270, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 185/500\n",
      "1040/1040 [==============================] - 0s 216us/step - loss: 0.0414 - accuracy: 0.9885 - val_loss: 0.0826 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.08270 to 0.08264, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 186/500\n",
      "1040/1040 [==============================] - 0s 267us/step - loss: 0.0411 - accuracy: 0.9885 - val_loss: 0.0825 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.08264 to 0.08250, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 187/500\n",
      "1040/1040 [==============================] - 0s 240us/step - loss: 0.0409 - accuracy: 0.9885 - val_loss: 0.0824 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.08250 to 0.08237, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 188/500\n",
      "1040/1040 [==============================] - 0s 192us/step - loss: 0.0406 - accuracy: 0.9885 - val_loss: 0.0822 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.08237 to 0.08225, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 189/500\n",
      "1040/1040 [==============================] - 0s 261us/step - loss: 0.0403 - accuracy: 0.9894 - val_loss: 0.0821 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.08225 to 0.08210, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 190/500\n",
      "1040/1040 [==============================] - 0s 221us/step - loss: 0.0401 - accuracy: 0.9904 - val_loss: 0.0819 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.08210 to 0.08193, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 191/500\n",
      "1040/1040 [==============================] - 0s 279us/step - loss: 0.0398 - accuracy: 0.9904 - val_loss: 0.0818 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.08193 to 0.08184, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 192/500\n",
      "1040/1040 [==============================] - 0s 221us/step - loss: 0.0396 - accuracy: 0.9904 - val_loss: 0.0817 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.08184 to 0.08167, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 193/500\n",
      "1040/1040 [==============================] - 0s 170us/step - loss: 0.0393 - accuracy: 0.9904 - val_loss: 0.0815 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.08167 to 0.08151, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 194/500\n",
      "1040/1040 [==============================] - 0s 269us/step - loss: 0.0391 - accuracy: 0.9904 - val_loss: 0.0814 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.08151 to 0.08142, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 195/500\n",
      "1040/1040 [==============================] - 0s 221us/step - loss: 0.0388 - accuracy: 0.9904 - val_loss: 0.0813 - val_accuracy: 0.9653\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.08142 to 0.08126, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 196/500\n",
      "1040/1040 [==============================] - 0s 241us/step - loss: 0.0386 - accuracy: 0.9904 - val_loss: 0.0812 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.08126 to 0.08115, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 197/500\n",
      "1040/1040 [==============================] - 0s 275us/step - loss: 0.0383 - accuracy: 0.9904 - val_loss: 0.0810 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.08115 to 0.08101, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 198/500\n",
      "1040/1040 [==============================] - 0s 194us/step - loss: 0.0381 - accuracy: 0.9904 - val_loss: 0.0809 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.08101 to 0.08091, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 199/500\n",
      "1040/1040 [==============================] - 0s 247us/step - loss: 0.0378 - accuracy: 0.9923 - val_loss: 0.0808 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.08091 to 0.08079, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 200/500\n",
      "1040/1040 [==============================] - 0s 218us/step - loss: 0.0375 - accuracy: 0.9923 - val_loss: 0.0807 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.08079 to 0.08066, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 201/500\n",
      "1040/1040 [==============================] - 0s 241us/step - loss: 0.0373 - accuracy: 0.9923 - val_loss: 0.0805 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.08066 to 0.08055, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 202/500\n",
      "1040/1040 [==============================] - 0s 357us/step - loss: 0.0370 - accuracy: 0.9923 - val_loss: 0.0804 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.08055 to 0.08043, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 203/500\n",
      "1040/1040 [==============================] - 0s 146us/step - loss: 0.0368 - accuracy: 0.9923 - val_loss: 0.0803 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.08043 to 0.08029, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 204/500\n",
      "1040/1040 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.99 - 0s 256us/step - loss: 0.0365 - accuracy: 0.9923 - val_loss: 0.0801 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.08029 to 0.08012, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 205/500\n",
      "1040/1040 [==============================] - 0s 308us/step - loss: 0.0363 - accuracy: 0.9923 - val_loss: 0.0800 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.08012 to 0.08000, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 206/500\n",
      "1040/1040 [==============================] - 0s 250us/step - loss: 0.0360 - accuracy: 0.9923 - val_loss: 0.0799 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.08000 to 0.07994, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 207/500\n",
      "1040/1040 [==============================] - 0s 322us/step - loss: 0.0358 - accuracy: 0.9923 - val_loss: 0.0798 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.07994 to 0.07980, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 208/500\n",
      "1040/1040 [==============================] - 0s 158us/step - loss: 0.0355 - accuracy: 0.9923 - val_loss: 0.0797 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.07980 to 0.07967, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 209/500\n",
      "1040/1040 [==============================] - 0s 219us/step - loss: 0.0353 - accuracy: 0.9923 - val_loss: 0.0796 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.07967 to 0.07961, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 210/500\n",
      "1040/1040 [==============================] - 0s 223us/step - loss: 0.0351 - accuracy: 0.9923 - val_loss: 0.0795 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.07961 to 0.07950, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 211/500\n",
      "1040/1040 [==============================] - 0s 236us/step - loss: 0.0348 - accuracy: 0.9923 - val_loss: 0.0794 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.07950 to 0.07940, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 212/500\n",
      "1040/1040 [==============================] - 0s 226us/step - loss: 0.0346 - accuracy: 0.9933 - val_loss: 0.0792 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.07940 to 0.07923, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 213/500\n",
      "1040/1040 [==============================] - 0s 291us/step - loss: 0.0344 - accuracy: 0.9933 - val_loss: 0.0791 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.07923 to 0.07912, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 214/500\n",
      "1040/1040 [==============================] - 0s 260us/step - loss: 0.0341 - accuracy: 0.9933 - val_loss: 0.0790 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.07912 to 0.07902, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 215/500\n",
      "1040/1040 [==============================] - 0s 255us/step - loss: 0.0339 - accuracy: 0.9933 - val_loss: 0.0789 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.07902 to 0.07894, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 216/500\n",
      "1040/1040 [==============================] - 0s 203us/step - loss: 0.0337 - accuracy: 0.9933 - val_loss: 0.0788 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.07894 to 0.07885, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 217/500\n",
      "1040/1040 [==============================] - 0s 221us/step - loss: 0.0334 - accuracy: 0.9933 - val_loss: 0.0788 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.07885 to 0.07876, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 218/500\n",
      "1040/1040 [==============================] - 0s 326us/step - loss: 0.0332 - accuracy: 0.9933 - val_loss: 0.0787 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.07876 to 0.07865, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 219/500\n",
      "1040/1040 [==============================] - 0s 227us/step - loss: 0.0330 - accuracy: 0.9933 - val_loss: 0.0785 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.07865 to 0.07853, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 220/500\n",
      "1040/1040 [==============================] - 0s 178us/step - loss: 0.0328 - accuracy: 0.9933 - val_loss: 0.0784 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.07853 to 0.07841, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 221/500\n",
      "1040/1040 [==============================] - 0s 277us/step - loss: 0.0325 - accuracy: 0.9933 - val_loss: 0.0783 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.07841 to 0.07831, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 222/500\n",
      "1040/1040 [==============================] - 0s 117us/step - loss: 0.0323 - accuracy: 0.9933 - val_loss: 0.0782 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.07831 to 0.07820, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 223/500\n",
      "1040/1040 [==============================] - 0s 208us/step - loss: 0.0321 - accuracy: 0.9933 - val_loss: 0.0781 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.07820 to 0.07806, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 224/500\n",
      "1040/1040 [==============================] - 0s 290us/step - loss: 0.0319 - accuracy: 0.9933 - val_loss: 0.0779 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.07806 to 0.07793, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 225/500\n",
      "1040/1040 [==============================] - 0s 229us/step - loss: 0.0317 - accuracy: 0.9933 - val_loss: 0.0778 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.07793 to 0.07782, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 226/500\n",
      "1040/1040 [==============================] - 0s 214us/step - loss: 0.0315 - accuracy: 0.9933 - val_loss: 0.0777 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.07782 to 0.07771, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 227/500\n",
      "1040/1040 [==============================] - 0s 233us/step - loss: 0.0313 - accuracy: 0.9933 - val_loss: 0.0776 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.07771 to 0.07758, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 228/500\n",
      "1040/1040 [==============================] - 0s 223us/step - loss: 0.0311 - accuracy: 0.9933 - val_loss: 0.0775 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.07758 to 0.07752, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 229/500\n",
      "1040/1040 [==============================] - 0s 213us/step - loss: 0.0309 - accuracy: 0.9933 - val_loss: 0.0774 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.07752 to 0.07738, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 230/500\n",
      "1040/1040 [==============================] - 0s 227us/step - loss: 0.0307 - accuracy: 0.9942 - val_loss: 0.0773 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.07738 to 0.07731, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 231/500\n",
      "1040/1040 [==============================] - 0s 254us/step - loss: 0.0305 - accuracy: 0.9942 - val_loss: 0.0773 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.07731 to 0.07727, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 232/500\n",
      "1040/1040 [==============================] - 0s 251us/step - loss: 0.0303 - accuracy: 0.9942 - val_loss: 0.0772 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.07727 to 0.07718, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 233/500\n",
      "1040/1040 [==============================] - 0s 269us/step - loss: 0.0301 - accuracy: 0.9942 - val_loss: 0.0770 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.07718 to 0.07704, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 234/500\n",
      "1040/1040 [==============================] - 0s 228us/step - loss: 0.0299 - accuracy: 0.9942 - val_loss: 0.0769 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.07704 to 0.07694, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 235/500\n",
      "1040/1040 [==============================] - 0s 255us/step - loss: 0.0297 - accuracy: 0.9942 - val_loss: 0.0769 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.07694 to 0.07691, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 236/500\n",
      "1040/1040 [==============================] - 0s 254us/step - loss: 0.0297 - accuracy: 0.9942 - val_loss: 0.0769 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.07691 to 0.07689, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 237/500\n",
      "1040/1040 [==============================] - 0s 208us/step - loss: 0.0296 - accuracy: 0.9942 - val_loss: 0.0769 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.07689 to 0.07686, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 238/500\n",
      "1040/1040 [==============================] - 0s 325us/step - loss: 0.0296 - accuracy: 0.9942 - val_loss: 0.0768 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.07686 to 0.07682, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 239/500\n",
      "1040/1040 [==============================] - 0s 248us/step - loss: 0.0296 - accuracy: 0.9942 - val_loss: 0.0768 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.07682 to 0.07679, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 240/500\n",
      "1040/1040 [==============================] - 0s 182us/step - loss: 0.0296 - accuracy: 0.9942 - val_loss: 0.0768 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.07679 to 0.07677, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 241/500\n",
      "1040/1040 [==============================] - 0s 233us/step - loss: 0.0296 - accuracy: 0.9942 - val_loss: 0.0767 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.07677 to 0.07675, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 242/500\n",
      "1040/1040 [==============================] - 0s 189us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0767 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.07675 to 0.07673, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 243/500\n",
      "1040/1040 [==============================] - 0s 268us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0767 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.07673 to 0.07671, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 244/500\n",
      "1040/1040 [==============================] - 0s 302us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0767 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.07671 to 0.07669, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 245/500\n",
      "1040/1040 [==============================] - 0s 251us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0767 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.07669 to 0.07668, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 246/500\n",
      "1040/1040 [==============================] - 0s 211us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0767 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.07668 to 0.07667, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 247/500\n",
      "1040/1040 [==============================] - 0s 201us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0767 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.07667 to 0.07666, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 248/500\n",
      "1040/1040 [==============================] - 0s 274us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0767 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.07666 to 0.07666, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 249/500\n",
      "1040/1040 [==============================] - 0s 288us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.07666 to 0.07665, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 250/500\n",
      "1040/1040 [==============================] - 0s 165us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.07665 to 0.07664, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 251/500\n",
      "1040/1040 [==============================] - 0s 266us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.07664 to 0.07664, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 252/500\n",
      "1040/1040 [==============================] - 0s 224us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.07664 to 0.07663, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 253/500\n",
      "1040/1040 [==============================] - 0s 201us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.07663 to 0.07663, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 254/500\n",
      "1040/1040 [==============================] - 0s 301us/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.07663 to 0.07662, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 255/500\n",
      "1040/1040 [==============================] - 0s 237us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.07662 to 0.07662, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 256/500\n",
      "1040/1040 [==============================] - 0s 208us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.07662 to 0.07662, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 257/500\n",
      "1040/1040 [==============================] - 0s 230us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.07662 to 0.07661, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 258/500\n",
      "1040/1040 [==============================] - 0s 171us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.07661 to 0.07661, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 259/500\n",
      "1040/1040 [==============================] - 0s 258us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.07661 to 0.07661, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 260/500\n",
      "1040/1040 [==============================] - 0s 307us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.07661 to 0.07661, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 261/500\n",
      "1040/1040 [==============================] - 0s 220us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00261: val_loss improved from 0.07661 to 0.07660, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 262/500\n",
      "1040/1040 [==============================] - 0s 244us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.07660 to 0.07660, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 263/500\n",
      "1040/1040 [==============================] - 0s 218us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.07660 to 0.07660, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 264/500\n",
      "1040/1040 [==============================] - 0s 244us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.07660 to 0.07660, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 265/500\n",
      "1040/1040 [==============================] - 0s 316us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.07660 to 0.07660, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 266/500\n",
      "1040/1040 [==============================] - 0s 230us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.07660 to 0.07660, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 267/500\n",
      "1040/1040 [==============================] - 0s 223us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.07660 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 268/500\n",
      "1040/1040 [==============================] - 0s 329us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00268: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 269/500\n",
      "1040/1040 [==============================] - 0s 226us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00269: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 270/500\n",
      "1040/1040 [==============================] - 0s 329us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00270: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 271/500\n",
      "1040/1040 [==============================] - 0s 207us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00271: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 272/500\n",
      "1040/1040 [==============================] - 0s 241us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 273/500\n",
      "1040/1040 [==============================] - 0s 274us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 274/500\n",
      "1040/1040 [==============================] - 0s 227us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00274: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 275/500\n",
      "1040/1040 [==============================] - 0s 217us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00275: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00275: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 276/500\n",
      "1040/1040 [==============================] - 0s 221us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00276: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 277/500\n",
      "1040/1040 [==============================] - 0s 231us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 278/500\n",
      "1040/1040 [==============================] - 0s 251us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 279/500\n",
      "1040/1040 [==============================] - 0s 246us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00279: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 280/500\n",
      "1040/1040 [==============================] - 0s 212us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 281/500\n",
      "1040/1040 [==============================] - 0s 217us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 282/500\n",
      "1040/1040 [==============================] - 0s 200us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00282: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 283/500\n",
      "1040/1040 [==============================] - 0s 242us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 284/500\n",
      "1040/1040 [==============================] - 0s 241us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 285/500\n",
      "1040/1040 [==============================] - 0s 201us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00285: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00285: val_loss improved from 0.07659 to 0.07659, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 286/500\n",
      "1040/1040 [==============================] - 0s 233us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.07659 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 287/500\n",
      "1040/1040 [==============================] - 0s 212us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 288/500\n",
      "1040/1040 [==============================] - 0s 305us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 289/500\n",
      "1040/1040 [==============================] - 0s 245us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 290/500\n",
      "1040/1040 [==============================] - 0s 355us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00290: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 291/500\n",
      "1040/1040 [==============================] - 0s 256us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 292/500\n",
      "1040/1040 [==============================] - 0s 246us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 293/500\n",
      "1040/1040 [==============================] - 0s 260us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 294/500\n",
      "1040/1040 [==============================] - 0s 229us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00294: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 295/500\n",
      "1040/1040 [==============================] - 0s 241us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00295: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00295: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 296/500\n",
      "1040/1040 [==============================] - 0s 247us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00296: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 297/500\n",
      "1040/1040 [==============================] - 0s 224us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00297: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 298/500\n",
      "1040/1040 [==============================] - 0s 271us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 299/500\n",
      "1040/1040 [==============================] - 0s 258us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00299: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 300/500\n",
      "1040/1040 [==============================] - 0s 216us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 301/500\n",
      "1040/1040 [==============================] - 0s 327us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00301: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 302/500\n",
      "1040/1040 [==============================] - 0s 214us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 303/500\n",
      "1040/1040 [==============================] - 0s 269us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00303: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 304/500\n",
      "1040/1040 [==============================] - 0s 250us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00304: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 305/500\n",
      "1040/1040 [==============================] - 0s 221us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00305: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 306/500\n",
      "1040/1040 [==============================] - 0s 242us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 307/500\n",
      "1040/1040 [==============================] - 0s 221us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.07658\n",
      "Epoch 308/500\n",
      "1040/1040 [==============================] - 0s 294us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00308: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 309/500\n",
      "1040/1040 [==============================] - 0s 236us/step - loss: 0.0294 - accuracy: 0.9942 - val_loss: 0.0766 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.07658 to 0.07658, saving model to ./210512_maxpool3/model/Check_residual3_filter4_fold2_0512.h5\n",
      "Epoch 00309: early stopping\n"
     ]
    }
   ],
   "source": [
    "data_x = np.load(savepath+'/npy/train_x_fold2.npy')\n",
    "data_y = np.load(savepath+'/npy/train_y_fold2.npy')\n",
    "# train_x,test_x,val_y,val_y = train_test_split(data_x,data_y, stratify = data_y, train_size=1300, random_state = 25)\n",
    "train_x,val_x,train_y,val_y = train_test_split(data_x,data_y, stratify = data_y, train_size=1040)\n",
    "input_img = Input(shape=(32,32,1))\n",
    "model = base_classification_jw(input_img, filters = 4, scale = 2)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=savepath+'/model/Check_residual3_filter4_fold2_0512.h5', verbose=1, save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=10, min_lr=0, min_delta=0.001, verbose=1)\n",
    "earlystopper = EarlyStopping(patience=30, verbose=1, monitor='loss')\n",
    "callbacks_list = [reduce_lr, checkpointer, earlystopper]\n",
    "\n",
    "# results = model.fit(train_x, train_y, batch_size=128, epochs=500, verbose=1, validation_split=0.2, shuffle=False, callbacks=callbacks_list)\n",
    "results = model.fit(train_x, train_y, batch_size=128, epochs=500, verbose=1, validation_data=(val_x,val_y), shuffle=False, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325/325 [==============================] - 2s 6ms/step\n",
      "149 14 151 11\n",
      "###########RESULT########\n",
      "AUC:0.974, SEN:0.931, SPEC:0.915, ACC:0.923, PREC:149.0\n",
      "TP:149, FP:14. TN:151, FN:11\n",
      "#########################\n"
     ]
    }
   ],
   "source": [
    "cknum = 2\n",
    "test_model = load_model(savepath+'/model/Check_residual3_filter4_fold{}_0512.h5'.format(str(cknum)))\n",
    "test_x= np.load(savepath+'/npy/test_x_fold{}.npy'.format(str(cknum)))\n",
    "test_y= np.load(savepath+'/npy/test_y_fold{}.npy'.format(str(cknum)))\n",
    "test_result= test_model.predict(test_x, batch_size=128, verbose=1)\n",
    "np.save(savepath+'/npy/Check_test_result_fold{}.npy'.format(str(cknum)), test_result)\n",
    "fpr_res,tpr_res,_=roc_curve(test_y,test_result)\n",
    "auc_res=auc(fpr_res, tpr_res)\n",
    "#     print(\"loss: %.2f, 정확도: %.3f  \" %(score[0], score[1]))\n",
    "res_tp, res_fp, res_tn, res_fn, res_sensitivity, res_specificity, acc, prec= calculate_performance(test_result, test_y)\n",
    "\n",
    "performanceList = [auc_res, res_sensitivity, res_specificity, acc]\n",
    "for a in range(4):\n",
    "    performances[i][a] = performanceList[a]\n",
    "\n",
    "#     interp_tpr = np.interp(mean_fpr, _, _)\n",
    "#     interp_tpr[0] = 0.0\n",
    "#     tprs.append(interp_tpr)\n",
    "#     np.save('./210512/npy/performanceList_fold{}.npy'.format(str(i)), performances)\n",
    "print('###########RESULT########')\n",
    "print('AUC:{}, SEN:{}, SPEC:{}, ACC:{}, PREC:{}'.format(round(auc_res,3),round(res_sensitivity,3),round(res_specificity,3),round(acc,3),round(prec,3)))\n",
    "print('TP:{}, FP:{}. TN:{}, FN:{}'.format(res_tp, res_fp, res_tn, res_fn))\n",
    "print('#########################')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fdcbc786780>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "confusionMatrix = confusion_matrix(lab_test, predicts)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusionMatrix)\n",
    "\n",
    "disp.plot(cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
